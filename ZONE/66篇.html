<!DOCTYPE  html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="zh-cn" lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>66篇</title><meta name="author" content="slow 慢的"/><style type="text/css"> * {margin:0; padding:0; text-indent:0; }
 .p, p { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; margin:0pt; }
 .s1 { color: #FFF; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s2 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s3 { color: #FFF; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s4 { color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s5 { color: #FFF; font-family:等线; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s6 { color: black; font-family:等线; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 .s7 { color: #4B4E4D; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 11pt; }
 .s8 { color: black; font-family:等线; font-style: normal; font-weight: normal; text-decoration: none; font-size: 10pt; }
 li {display: block; }
 #l1 {padding-left: 0pt; }
 #l1> li>*:first-child:before {content: "- "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l2 {padding-left: 0pt;counter-reset: d1 1; }
 #l2> li>*:first-child:before {counter-increment: d1; content: counter(d1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l2> li:first-child>*:first-child:before {counter-increment: d1 0;  }
 li {display: block; }
 #l3 {padding-left: 0pt;counter-reset: e1 1; }
 #l3> li>*:first-child:before {counter-increment: e1; content: counter(e1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l3> li:first-child>*:first-child:before {counter-increment: e1 0;  }
 li {display: block; }
 #l4 {padding-left: 0pt;counter-reset: f1 1; }
 #l4> li>*:first-child:before {counter-increment: f1; content: counter(f1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l4> li:first-child>*:first-child:before {counter-increment: f1 0;  }
 li {display: block; }
 #l5 {padding-left: 0pt;counter-reset: g1 1; }
 #l5> li>*:first-child:before {counter-increment: g1; content: counter(g1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l5> li:first-child>*:first-child:before {counter-increment: g1 0;  }
 li {display: block; }
 #l6 {padding-left: 0pt;counter-reset: h1 1; }
 #l6> li>*:first-child:before {counter-increment: h1; content: counter(h1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l6> li:first-child>*:first-child:before {counter-increment: h1 0;  }
 li {display: block; }
 #l7 {padding-left: 0pt;counter-reset: i1 1; }
 #l7> li>*:first-child:before {counter-increment: i1; content: counter(i1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l7> li:first-child>*:first-child:before {counter-increment: i1 0;  }
 li {display: block; }
 #l8 {padding-left: 0pt;counter-reset: j1 1; }
 #l8> li>*:first-child:before {counter-increment: j1; content: counter(j1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l8> li:first-child>*:first-child:before {counter-increment: j1 0;  }
 li {display: block; }
 #l9 {padding-left: 0pt;counter-reset: k1 1; }
 #l9> li>*:first-child:before {counter-increment: k1; content: counter(k1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l9> li:first-child>*:first-child:before {counter-increment: k1 0;  }
 li {display: block; }
 #l10 {padding-left: 0pt;counter-reset: l1 1; }
 #l10> li>*:first-child:before {counter-increment: l1; content: counter(l1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l10> li:first-child>*:first-child:before {counter-increment: l1 0;  }
 li {display: block; }
 #l11 {padding-left: 0pt;counter-reset: m1 1; }
 #l11> li>*:first-child:before {counter-increment: m1; content: counter(m1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l11> li:first-child>*:first-child:before {counter-increment: m1 0;  }
 li {display: block; }
 #l12 {padding-left: 0pt;counter-reset: n1 1; }
 #l12> li>*:first-child:before {counter-increment: n1; content: counter(n1, upper-latin)" "; color: black; font-family:"Times New Roman", serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 14pt; }
 #l12> li:first-child>*:first-child:before {counter-increment: n1 0;  }
 table, tbody {vertical-align: top; overflow: visible; }
</style></head><body><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">SPECIATION IN GEOGRAPHICALLY ISOLATED POPULATIONS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO31</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Evolutionary biologists believe that speciation, the formation of a new species, often begins when some kind of physical barrier arises and divides a population of a single species into separate subpopulations. Physical separation between subpopulations promotes the formation of new species because once the members of one subpopulation can no longer mate with members of another subpopulation, they cannot exchange variant genes that arise in one of the subpopulations. In the absence of gene flow between the subpopulations, genetic differences between the groups begin to accumulate. Eventually the subpopulations become so genetically distinct that they cannot interbreed even if the physical barriers between them were removed. At this point the subpopulations have evolved into distinct species. This route to speciation is known as allopatry (“allo-” means “different”, and “patria” means “homeland”).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Allopatric speciation may be the main speciation route. This should not be surprising, since allopatry is pretty common. In general, subpopulations of most species are separated from each other by some measurable distance. So even under normal situations the gene flow among the subpopulations is more of an intermittent trickle than a steady stream. In addition, barriers can rapidly arise and shut off the trickle. For example, in the 1800s a monstrous earthquake changed the course of the Mississippi River, a large river flowing in the central part of the United States of America. The change separated populations of insects now living along opposite shores, completely cutting off gene flow between them.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Geographic isolation can also proceed slowly, over great spans of time. We find evidence of such extended events in the fossil record, which affords glimpse into the breakup of formerly continuous environments. For example, during past ice ages, glaciers advanced down through North America and Europe and gradually cut off parts of populations from one another. When the glaciers retreated, the separated populations of plants and animals came into contact again. Some groups that had descended from the same parent population were no longer reproductively compatible – they had evolved into separate species. In other groups, however, genetic divergences had not proceeded so far, and the descendants could still interbreed – for them, reproductive isolation was not completed, and so speciation had not occurred.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Allopatric speciation can also be brought by the imperceptibly slow but colossal movements of the tectonic plates that make up Earth’s surface. About 5 million years ago such geologic movements created the land bridge between North America and South America that we call the Isthmus of Panama . While previously the gap between the continents had allowed a free flow of water, now the isthmus presented a barrier that divided the Atlantic Ocean from the Pacific Ocean. This division set the stage for allopatric speciation among populations of fishes and other marine species.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">In the 1980s, John Graves studied two populations of closely related fishes, one population from the Atlantic side of isthmus, the other from the Pacific side. He compared four enzymes found in the muscles of each population. Graves found that all four Pacific enzymes function better at lower temperatures than the four Atlantic versions of the same enzymes. This is significant because Pacific seawater is typically 2 to 3 degrees cooler than seawater on the Atlantic side of isthmus. Analysis by gel electrophoresis revealed slight differences in amino acid sequence of the enzymes of two of the four pairs. This is significant because the amino acid sequence of an enzyme is determined by genes.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Graves drew two conclusions from these observations. First, at least some of the observed differences between the enzymes of the Atlantic and Pacific fish populations were not random but were the result of evolutionary adaptation. Second, it appears that closely related populations of fishes on both sides of the isthmus are starting to genetically diverge from each other. Because Graves’ study of geographically isolated populations of isthmus fishes offers a glimpse of the beginning of a process of gradual accumulation of mutations that are neutral or adaptive, divergences here might be evidence of allopatric speciation in process.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;">  EARLY CHILDHOOD EDUCATION                                                                         </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 31pt;text-align: justify;">Preschools—educational programs for children under the age of five—differ significantly from one country to another according to the views that different societies hold regarding the purpose of early childhood education. For instance, in a cross-country comparison of preschools in China, Japan, and the United States, researchers found that parents in the three countries view the purpose of preschools very differently. Whereas parents in China tend to see preschools primarily as a way of giving children a good start academically, Japanese parents view them primarily as a way of giving children the opportunity to be members of a group. In the United States, in comparison, parents regard the primary purpose of preschools as making children more independent and self- reliant, although obtaining a good academic start and having group experience are also important.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 28pt;text-align: justify;">While many programs designed for preschoolers focus primarily on social and emotional factors, some are geared mainly toward promoting cognitive gains and preparing preschoolers for the formal instruction they will experience when they start kindergarten. In the United States, the best-known program designed to promote future academic success is Head Start. Established in the 1960s when the United States declared the War on Poverty, the program has served over 13 million children and their families. The program, which stresses parental involvement, was designed to serve the &quot;whole child&quot;, including children’s physical health, self-confidence, social responsibility, and social and emotional development.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 27pt;text-align: justify;">Whether Head Start is seen as successful or not depends on the lens through which one is looking. If, for instance, the program is expected to provide long-term increases in IQ (intelligence quotient) scores, it is a disappointment. Although graduates of Head Start programs tend to show immediate IQ gains, these increases do lot last. On the other hand, it is clear that Head Start is meeting its goal of getting preschoolers ready for school.  Preschoolers who participate  in Head Start are  better prepared for future schooling than those who do not. Furthermore, graduates of Head Start programs have better future school grade. Finally, some research suggests that ultimately Head Start graduates show higher academic performance at the end of high school, although the gains are modest.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 27pt;text-align: justify;">In addition, results from other types of preschool readiness programs indicate that those who participate and graduate are less likely to repeat grades, and they are more likely to complete school, for every dollar spent on the program, taxpayers saved seven dollars by the time the graduates reached the age of 27.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 27pt;text-align: justify;">The most recent comprehensive evaluation of early intervention programs suggests that, taken as a group, preschool programs can provide significant benefits, and that government funds invested early in life may ultimately lead to a reduction in future costs. For instance, compared with children who did not participate in early intervention programs, participants in various programs showed gains in emotional or cognitive development, better educational outcomes, increased economic self-sufficiency, reduced levels of criminal activity, and improved health-related behaviors. Of course, not every program produced all these benefits, and not every child benefited to the same extent. Furthermore, some researchers argue that less-expensive programs are just as good as relatively expensive ones, such as Head Start. Still, the results of the evaluation were promising, suggesting that the potential benefits of early intervention can be substantial.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Not everyone agrees that programs that seek to enhance academic skills during the preschool years are a good thing. In fact, according to developmental psychologist David Elkind, United States society tends to push children so rapidly that they begin to feel stress and pressure at a young age. Elkind argues that academic success is largely dependent upon factors out of parents’ control, such as inherited abilities and a child’s rate of maturation. Consequently, children of a particular age cannot be expected to master educational material without taking into account their current level of cognitive development. In short, children require development appropriate educational practice, which is education that is based on both typical development and the unique characteristics of a given child.</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> SAVANNA FORMATION                                                                                             </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Located in tropical areas at low altitudes, savannas are stable ecosystems, some wet and some dry consisting of vast grasslands with scattered trees or shrubs. They occur on a wide range of soil types and in extremes of climate. There is no simple or single factor that determines if a given site will be a savanna, but some factors seem to play important roles in their formation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Savannas typically experience a rather prolonged dry season. One theory behind savanna formation is that wet forest species are unable to withstand the dry season, and thus savanna, rather than rain forest, is favored on the site. Savannas experience an annual rainfall of between 1,000 and 2,000 millimeters, most of it falling in a five- to eight-month wet season. Though plenty of rain may fall on a savanna during the year, for at least part of the year little does, creating the drought stress ultimately favoring grasses. Such conditions prevail throughout much of northern South America and Cuba, but many Central American savannas as well as coastal areas of Brazil and the island of Trinidad do not fit this pattern. In these areas, rainfall per month exceeds that in the above definition, so other factors must contribute to savanna formation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In many characteristics, savanna soils are similar to those of some rain forests, though more extreme. For example, savanna soils, like many rain forest soils, are typically oxisols (dominated by certain oxide minerals) and ultisols (soils containing no calcium carbonate), with a high acidity and notably low concentrations of such minerals as phosphorus, calcium, magnesium, and potassium, while aluminum levels are high. Some savannas occur on wet, waterlogged soils; others on dry, sandy, well-drained soils. This may seem contradictory, but it only means that extreme soil conditions, either too wet or too dry for forests, are satisfactory for savannas. More moderate conditions support moist forests.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Waterlogged soils occur in areas that are flat or have poor drainage. These soils usually contain large amounts of clay and easily become water-saturated. Air cannot penetrate between the soil particles, making the soil oxygen‐poor. By contrast, dry soils are sandy and porous, their coarse textures permitting water to drain rapidly. Sandy soils are prone to the leaching of nutrients and minerals and so tend to be nutritionally poor. Though, most savannas are found on sites with poor soils (because of either moisture conditions or nutrient levels of both), poor soils can and do support lush rain forest.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Most savannas probably experience mild fires frequently and major burns every two years or so. Many savanna and dry‐forest plant species are called pyrophytes, meaning they are adapted in various ways to withstand occasional burning. Frequent fire is a factor to which rain forest species seem unable to adapt, although ancient charcoal remains from Amazon forest soil dating prior to the arrival of humans suggests that moist forests also occasionally burn. Experiments suggest that if fire did not occur in savannas in the Americas, species composition would change significantly. When</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">burning occurs, it prevents competition among plant species from progressing to the point where some species exclude others, reducing the overall diversity of the ecosystem. But in experimental areas protected from fire, a few perennial grass species eventually come to dominate, outcompeting all others. Evidence from other studies suggests that exclusion of fire results in markedly decreased plant‐species richness, often with an increase in tree density. There is generally little doubt that fire is a significant factor in maintaining savanna, certainly in most regions.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">On certain sites, particularly in South America, savanna formation seems related to frequent cutting and burning of moist forests for pastureland. Increase in pastureland and subsequent overgrazing have resulted in an expansion of savanna. The thin upper layer of humus (decayed organic matter) is destroyed by cutting and burning. Humus is necessary for rapid decomposition of leaves by bacteria and fungi and for recycling by surface roots. Once the humus layer disappears, nutrients cannot be recycled and leach from the soil, converting soil from fertile to infertile and making it suitable only for savanna vegetation. Forests on white, sandy soil are most susceptible to permanent alteration.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">PLANT COLONIZATION</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO32</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Colonization is one way in which plants can change the ecology of a site. Colonization is a process with two components: invasion and survival. The rate at which a site is colonized by plants depends on both the rate at which individual organisms (seeds, spores, immature or mature individuals) arrive at the site and their success at becoming established and surviving. Success in colonization depends to a great extent on there being a site available for colonization—a safe site where disturbance by fire or by cutting down of trees has either removed competing species or reduced levels of competition and other negative interactions to a level at which the invading species can become established. For a given rate of invasion, colonization of a moist, fertile site is likely to be much more rapid than that of a dry, infertile site because of poor survival on the latter. A fertile, plowed field is rapidly invaded by a large variety of weeds, whereas a neighboring construction site from which the soil has been compacted or removed to expose a coarse, infertile parent material may remain virtually free of vegetation for many months or even years despite receiving the same input of seeds as the plowed field.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Both the rate of invasion and the rate of extinction vary greatly among different plant species.Pioneer species—those that occur only in the earliest stages of colonization—tend to have high rates of invasion because they produce very large numbers of reproductive propagules (seeds, spores, and so on) and because they have an efficient means of dispersal (normally, wind).</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">If colonizers produce short-lived reproductive propagules, then they must produce very large numbers unless they have an efficient means of dispersal to suitable new habitats. Many plants depend on wind for dispersal and produce abundant quantities of small, relatively short-lived seeds to compensate for the fact that wind is not always a reliable means of reaching the appropriate type of habitat. Alternative strategies have evolved in some plants, such as those that produce fewer but larger seeds that are dispersed to suitable sites by birds or small mammals or those that produce long-lived seeds. Many forest plants seem to exhibit the latter adaptation, and viable seeds of pioneer species can be found in large numbers on some forest floors. For example, as many as 1,125 viable seeds per square meter were found in a 100-year-old Douglas fir/western hemlock forest in coastal British Columbia. Nearly all the seeds that had germinated from this seed bank were from pioneer species. The rapid colonization of such sites after disturbance is undoubtedly in part a reflection of the large seed bank on the forest floor.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">An adaptation that is well developed in colonizing species is a high degree of variation in germination (the beginning of a seed’s growth). Seeds of a given species exhibit a wide range of germination dates, increasing the probability that at least some of the seeds will germinate during a period of favorable environmental conditions. This is particularly important for species that colonize an environment where there is no existing vegetation to ameliorate climatic extremes and in which there may be great climatic diversity.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Species succession in plant communities, i.e., the temporal sequence of appearance and disappearance of species, is dependent on events occurring at different stages in the life history of a species. Variation in rates of invasion and growth plays an important role in determining patterns of succession, especially secondary succession. The species that are first to colonize a site are those that produce abundant seed that is distributed successfully to new sites. Such species generally grow rapidly and quickly dominate new sites, excluding other species with lower invasion and growth rates. The first community that occupies a disturbed area therefore may be composed of species with the highest rate of invasion, whereas the community of the subsequent stage may consist of plants with similar survival rates but lower invasion rates.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> SIAM, 1851-1910                                                                                                            </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">In the late nineteenth century, political and social changes were occurring rapidly in Siam (now Thailand). The old ruling families were being displaced by an evolving centralized government. These families were pensioned off (given a sum of money to live on) or simply had their revenues taken away or restricted; their sons were enticed away to schools for district officers, later to be posted in some faraway province; and the old patron-client relations that had bound together local societies simply disintegrated. Local rulers could no longer protect their relatives and attendants in legal cases, and with the ending in 1905 of the practice of forcing peasant farmers to work</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">part-time for local rulers, the rulers no longer had a regular base for relations with rural populations. The old local ruling families, then, were severed from their traditional social context.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The same situation viewed from the perspective of the rural population is even more complex. According to the government’s first census of the rural population, taken in 1905, there were about thirty thousand villages in Siam. This was probably a large increase over the figure even two or three decades earlier, during the late 1800s. It is difficult to imagine it now, but Siam’s Central Plain in the late 1800s was nowhere near as densely settled as it is today. There were still forests closely surrounding Bangkok into the last half of the nineteenth century, and even at century’s end there were wild elephants and tigers roaming the countryside only twenty or thirty miles away.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Much population movement involved the opening up of new lands for rice cultivation. Two things made this possible and encouraged it to happen. First, the opening of the kingdom to the full force of international trade by the Bowring Treaty (1855) rapidly encouraged economic specialization in the growing of rice, mainly to feed the rice-deficient portions of Asia (India and China in particular). The average annual volume of rice exported from Siam grew from under 60 million kilograms per year in the late 1850s to more than 660 million kilograms per year at the turn of the century; and over the same period the average price per kilogram doubled. During the same period, the area planted in rice increased from about 230,000 acres to more than 350,000 acres. This growth was achieved as the result of the collective decisions of thousands of peasant families to expand the amount of land they cultivated, clear and plant new land, or adopt more intensive methods of agriculture.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">They were able to do so because of our second consideration. They were relatively freer than they had been half a century earlier. Over the course of the Fifth Reign (1868– 1910), the ties that bound rural people to the aristocracy and local ruling elites were greatly reduced. Peasants now paid a tax on individuals instead of being required to render labor service to the government. Under these conditions, it made good sense to thousands of peasant families to in effect work full-time at what they had been able to do only part-time previously because of the requirement to work for the government: grow rice for the marketplace.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Numerous changes accompanied these developments. The rural population both dispersed and grew, and was probably less homogeneous and more mobile than it had been a generation earlier. The villages became more vulnerable to arbitrary treatment by government bureaucrats as local elites now had less control over them. By the early twentieth century, as government modernization in a sense caught up with what had been happening in the countryside since the 1870s, the government bureaucracy intruded more and more into village life. Provincial police began to appear, along with district officers and cattle registration and land deeds and registration for compulsory</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">military service. Village handicrafts diminished or died out completely as people bought imported consumer goods, like cloth and tools, instead of making them themselves. More economic variation took shape in rural villages, as some grew prosperous from farming while others did not. As well as can be measured, rural standards of living improved in the Fifth Reign. But the statistical averages mean little when measured against the harsh realities of peasant life.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> DISTRIBUTIONS OF TROPICAL BEE COLONIES                                               </span></p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">In 1977 ecologists Stephen Hubbell and Leslie Johnson recorded a dramatic example of how social interactions can produce and enforce regular spacing in a population. They studied competition and nest spacing in populations of stingless bees in tropical dry forests in Costa Rica. Though these bees do not sting, rival colonies of some species fight fiercely over potential nesting sites.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Stingless bees are abundant in tropical and subtropical environments, where they gather nectar and pollen from a wide variety of flowers. They generally nest in trees and live in colonies made up of hundreds to thousands of workers. Hubbell and Johnson observed that some species of stingless bees are highly aggressive to members of their species from other colonies, while other species are not. Aggressive species usually forage in groups and feed mainly on flowers that occur in high-density clumps. Nonaggressive species feed singly or in small groups and on more widely distributed flowers.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Hubbell and Johnson studied several species of stingless bees to determine whether there is a relationship between aggressiveness and patterns of colony distribution. They predicted that the colonies of aggressive species would show regular distributions, while those of nonaggressive species would show random or closely grouped (clumped) distributions. They concentrated their studies on a thirteen-hectare tract of tropical dry forest that contained numerous nests of nine species of stingless bees.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Though Hubbell and Johnson were interested in how bee behavior might affect colony distributions, they recognized that the availability of potential nest sites for colonies could also affect distributions. So as one of the first steps in their study, they mapped the distributions of trees suitable for nesting. They found that potential nest trees were distributed randomly through the study area. They also found that the number of potential nest sites was much greater than the number of bee colonies. What did these measurements show the researchers? The number of colonies in the study area was not limited by availability of suitable trees, and a clumped or regular distribution of colonies was not due to an underlying clumped or regular distribution of potential nest sites.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Hubbell and Johnson mapped the nests of five of the nine species of stingless bees accurately, and the nests of four of these species were distributed regularly. All four species with regular nest distributions were highly aggressive to bees from other</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">colonies of their own species. The fifth species was not aggressive, and its nests were randomly distributed over the study area.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The researchers also studied the process by which the aggressive species establish new colonies. Their observations provide insights into the mechanisms that establish and maintain the regular nest distribution of these species. Aggressive species apparently mark prospective nest sites with pheromones, chemical substances secreted by some animals for communication with other members of their species. The pheromone secreted by these stingless bees attracts and aggregates members of their colony to the prospective nest site; however, it also attracts workers from other nests.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">If workers from two different colonies arrive at the prospective nest at the same time, they may fight for possession. Fights may be escalated into protracted battles. The researchers observed battles over a nest tree that lasted for two weeks. Each dawn, fifteen to thirty workers from two competing colonies arrived at the contested nest site. The workers from the two colonies faced off in two swarms and displayed and fought with each other. In the displays, pairs of bees faced each other, slowly flew vertically to a height of about three meters, and then grappled each other to the ground. When the two bees hit the ground, they separated, faced off, and performed another aerial display. Bees did not appear to be injured in these fights, which were apparently ritualized. The two swarms abandoned the battle at about 8 or 9 A.M. each morning, only to reform and begin again the next day just after dawn. While this contest over an unoccupied nest site produced no obvious mortality, fights over occupied nests sometimes kill over 1,000 bees in a single battle.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:5.5pt" cellspacing="0"><tr style="height:22pt"><td style="width:496pt" colspan="4" bgcolor="#4471C4"><p class="s3" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO33</p></td></tr><tr style="height:38pt"><td style="width:282pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 2pt;padding-left: 4pt;padding-right: 11pt;text-indent: 0pt;text-align: left;">RAILROADS AND COMMERCIAL NINETEENTH-CENTURY</p></td><td style="width:129pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">AGRICULTURE</p></td><td style="width:39pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">IN</p></td><td style="width:46pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 2pt;padding-left: 11pt;text-indent: 0pt;text-align: left;">THE</p></td></tr></table><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">By 1850 the United States possessed roughly 9,000 miles of railroad track; ten years later it had over 30,000 miles, more than the rest of the world combined. Much of the new construction during the 1850s occurred west of the Appalachian Mountains—over 2,000 miles in the states of Ohio and Illinois alone.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The effect of the new railroad lines rippled outward through the economy. Farmers along the tracks began to specialize in crops that they could market in distant locations. With their profits they purchased manufactured goods that earlier they might have made at home. Before the railroad reached Tennessee, the state produced about 25,000 bushels (or 640 tons) of wheat, which sold for less than 50 cents a bushel. Once the railroad came, farmers in the same counties grew 400,000 bushels (over 10,000 tons) and sold their crop at a dollar a bushel.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">The new railroad networks shifted the direction of western trade. In 1840 most northwestern grain was shipped south down the Mississippi River to the bustling port of New Orleans. But low water made steamboat travel hazardous in summer, and ice shut down traffic in winter. Products such as lard, tallow, and cheese quickly spoiled if stored in New Orleans’ hot and humid warehouses. Increasingly, traffic from the Midwest flowed west to east, over the new rail lines. Chicago became the region’s hub, linking the farms of the upper Midwest to New York and other eastern cities by more than 2,000 miles of track in 1855. Thus while the value of goods shipped by river to New Orleans continued to increase, the South’s overall share of western trade dropped dramatically.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">A sharp rise in demand for grain abroad also encouraged farmers in the Northeast and Midwest to become more commercially oriented. Wheat, which in 1845 commanded $1.08 a bushel in New York City, fetched $2.46 in 1855; in similar fashion the price of corn nearly doubled. Farmers responded by specializing in cash crops, borrowing to purchase more land, and investing in equipment to increase productivity.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">As railroad lines fanned out from Chicago, farmers began to acquire open prairie land in Illinois and then Iowa, putting the fertile, deep black soil into production. Commercial agriculture transformed this remarkable treeless environment. To settlers accustomed to eastern woodlands, the thousands of square miles of tall grass were an awesome sight. Indian grass, Canada wild rye, and native big bluestem all grew higher than a person. Because eastern plows could not penetrate the densely tangled roots of prairie grass, the earliest settlers erected farms along the boundary separating the forest from the prairie. In 1837, however, John Deere patented a sharp-cutting steel plow that sliced through the sod without soil sticking to the blade. Cyrus McCormick refined a mechanical reaper that harvested fourteen times more wheat with the same amount of labor. By the 1850s McCormick was selling 1,000 reapers a year and could not keep up with demand, while Deere turned out 10,000 plows annually.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The new commercial farming fundamentally altered the midwestern landscape and the environment. Native Americans had grown corn in the region for years, but never in such large fields as did later settlers who became farmers, whose surpluses were shipped east. Prairie farmers also introduced new crops that were not part of the earlier ecological system, notably wheat, along with fruits and vegetables.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Native grasses were replaced by a small number of plants cultivated as commodities. Corn had the best yields, but it was primarily used to feed livestock. Because bread played a key role in the American and European diet, wheat became the major cash crop. Tame grasses replaced native grasses in pastures for making hay.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Western farmers altered the landscape by reducing the annual fires that had kept the prairie free from trees. In the absence of these fires, trees reappeared on land not in</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">cultivation and, if undisturbed, eventually formed woodlots. The earlier unbroken landscape gave way to independent farms, each fenced off in a precise checkerboard pattern. It was an artificial ecosystem of animals, woodlots, and crops, whose large, uniform layout made western farms more efficient than the more-irregular farms in the East.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> EXTINCTION EPISODES OF THE PAST                                                                 </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">It was not until the Cambrian period, beginning about 600 million years ago, that a great proliferation of macroscopic species occurred on Earth and produced a fossil record that allows us to track the rise and fall of biodiversity. Since the Cambrian period, biodiversity has generally risen, but there have been some notable exceptions. Biodiversity collapsed dramatically during at least five periods because of mass extinctions around the globe. The five major mass extinctions receive most of the attention, but they are only one end of a spectrum of extinction events. Collectively, more species went extinct during smaller events that were less dramatic but more frequent. The best known of the five major extinction events, the one that saw the demise of the dinosaurs, is the Cretaceous-Tertiary extinction.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Starting about 280 million years ago, reptiles were the dominant large animals in terrestrial environments. In popular language this was the era “when dinosaurs ruled Earth,” with a wide variety of reptile species occupying many ecological niches. However, no group or species can maintain its dominance indefinitely, and when, after over 200 million years, the age of dinosaurs came to a dramatic end about 65 million years ago, mammals began to flourish, evolving from relatively few types of small terrestrial animals into the myriad of diverse species, including bats and whales, that we know  today.  Paleontologists label  this point  in Earth’s  history  as  the  end of the Cretaceous period and the beginning of the Tertiary period, often abbreviated as the K- T boundary. This time was also marked by changes in many other types of organisms. Overall, about 38 percent of the families of marine animals were lost, with percentages much higher in some groups. Ammonoid mollusks went from being very diverse and abundant to being extinct. An extremely abundant set of planktonic marine animals called foraminifera largely disappeared, although they rebounded later. Among plants, the K-T boundary saw a sharp but brief rise in the abundance of primitive vascular plants such as ferns, club mosses, horsetails, and conifers and other gymnosperms. The number of flowering plants (angiosperms) was reduced at this time, but they then began to increase dramatically.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">What caused these changes? For many years scientists assumed that a cooling of the climate was responsible, with dinosaurs being particularly vulnerable because, like modern reptiles, they were ectothermic (dependent on environmental heat, or cold- blooded). It is now widely believed that at least some species of dinosaurs had a metabolic rate high enough for them to be endotherms (animals that maintain a</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">relatively consistent body temperature by generating heat internally). Nevertheless, climatic explanations for the K-T extinction are not really challenged by the idea that dinosaurs may have been endothermic, because even endotherms can be affected by a significant change in the climate.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Explanations for the K-T extinction were revolutionized in 1980 when a group of physical scientists led by Luis Alvarez proposed that 65 million years ago Earth was struck by a 10-kilometer-wide meteorite traveling at 90,000 kilometers per hour. They believed that this impact generated a thick cloud of dust that enveloped Earth, shutting out much of the incoming solar radiation and reducing plant photosynthesis to very low levels. Short-term effects might have included huge tidal waves and extensive fires. In other words, a series of events arising from a single cataclysmic event caused the massive extinctions. Initially, the meteorite theory was based on a single line of evidence.  At locations around the globe, geologists had found an unusually high concentration of iridium in the layer of sedimentary rocks that was formed about 65 million years ago. Iridium is an element that is usually uncommon near Earth’s surface, but it is abundant in some meteorites. Therefore, Alvarez and his colleagues concluded that it was likely that the iridium in sedimentary rocks deposited at the K-T boundary had originated in a giant meteorite or asteroid. Most scientists came to accept the meteorite theory after evidence came to light that a circular formation, 180 kilometers in diameter and centered on the north coast of the Yucatán Peninsula, was created by a meteorite impact about 65 million years ago.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> THE FIRST CIVILIZATIONS                                                                                      </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Evidence suggests that an important stimulus behind the rise of early civilizations was the development of settled agriculture, which unleashed a series of changes in the organization of human communities that culminated in the rise of large ancient empires.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The exact time and place that crops were first cultivated successfully is uncertain. Many prehistorians believe that farming may have emerged independently in several different areas of the world when small communities, driven by increasing population and a decline in available food resources, began to plant seeds in the ground in an effort to guarantee their survival. The first farmers, who may have lived as long as 10,000 years ago, undoubtedly used simple techniques and still relied primarily on other forms of food production, such as hunting, foraging, or pastoralism. The real breakthrough took place when farmers began to cultivate crops along the floodplains of river systems. The advantage was that crops grown in such areas were not as dependent on rainfall and therefore produced a more reliable harvest. An additional benefit was that the sediment carried by the river waters deposited nutrients in the soil, thus enabling the farmer to cultivate a single plot of ground for many years without moving to a new location. Thus, the first truly sedentary (that is, nonmigratory) societies were born. As time went on, such communities gradually learned how to direct the flow of water to enhance the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">productive capacity of the land, while the introduction of the iron plow eventually led to the cultivation of heavy soils not previously susceptible to agriculture.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The spread of this river valley agriculture in various parts of Asia and Africa was the decisive factor in the rise of the first civilizations. The increase in food production in these regions led to a significant growth in population, while efforts to control the flow of water to maximize the irrigation of cultivated areas and to protect the local inhabitants from hostile forces outside the community provoked the first steps toward cooperative activities on a large scale. The need to oversee the entire process brought about the emergence of an elite that was eventually transformed into a government.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The first clear steps in the rise of the first civilizations took place in the fourth and third millennia B.C. in Mesopotamia, northern Africa, India, and China. How the first governments took shape in these areas is not certain, but anthropologists studying the evolution of human communities in various parts of the world have discovered that one common stage in the process is the emergence of what are called “big men” within a single village or a collection of villages. By means of their military prowess, dominant personalities, or political talent, these people gradually emerge as the leaders of that community. In time, the “big men” become formal symbols of authority and pass on that authority to others within their own family. As the communities continue to grow in size and material wealth, the “big men” assume hereditary status, and their allies and family members are transformed into a hereditary monarchy.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The appearance of these sedentary societies had a major impact on the social organizations, religious beliefs, and way of life of the peoples living within their boundaries. With the increase in population and the development of centralized authority came the emergence of the cities. While some of these urban centers were identified with a particular economic function, such as proximity to gold or iron deposits or a strategic location on a major trade route, others served primarily as administrative centers or the site of temples for the official cult or other ritual observances. Within these cities, new forms of livelihood appeared to satisfy the growing need for social services and consumer goods. Some people became artisans or merchants, while others became warriors, scholars, or priests. In some cases, the physical division within the first cities reflected the strict hierarchical character of the society as a whole, with a royal palace surrounded by an imposing wall and separate from the remainder of the urban population. In other instances, such as the Indus River Valley, the cities lacked a royal precinct and the ostentatious palaces that marked their contemporaries elsewhere.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">PROTECTION OF PLANTS BY INSECTS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO34</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">Many plants—one or more species of at least 68 different families—can secrete nectar even when they have no blossoms, because they bear extrafloral nectaries (structures</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">that produce nectar) on stems, leaves, leaf stems, or other structures. These plants usually occur where ants are abundant, most in the tropics but some in temperate areas. Among those of northeastern North America are various plums, cherries, roses, hawthorns, poplars, and oaks. Like floral nectar, extrafloral nectar consists mainly of water with a high content of dissolved sugars and, in some plants, small amounts of amino acids. The extrafloral nectaries of some plants are known to attract ants and other insects, but the evolutionary history of most plants with these nectaries is unknown. Nevertheless, most ecologists believe that all extrafloral nectaries attract insects that will defend the plant.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Ants are probably the most frequent and certainly the most persistent defenders of plants. Since the highly active worker ants require a great deal of energy, plants exploit this need by providing extrafloral nectar that supplies ants with abundant energy. To return this favor, ants guard the nectaries, driving away or killing intruding insects that might compete with ants for nectar. Many of these intruders are herbivorous and would eat the leaves of the plants.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Biologists once thought that secretion of extrafloral nectar has some purely internal physiological function, and that ants provide no benefit whatsoever to the plants that secrete it. This view and the opposing “protectionist” hypothesis that ants defend plants had been disputed for over a hundred years when, in 1910, a skeptical William Morton Wheeler commented on the controversy. He called for proof of the protectionist view: that visitations of the ants confer protection on the plants and that in the absence of the insects a much greater number would perish or fail to produce flowers or seeds than when the insects are present. That we now have an abundance of the proof that was called for was established when Barbara Bentley reviewed the relevant evidence in 1977, and since then many more observations and experiments have provided still further proof that ants benefit plants.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One example shows how ants attracted to extrafloral nectaries protect morning glories against attacking insects. The principal insect enemies of the North American morning glory feed mainly on its flowers or fruits rather than its leaves. Grasshoppers feeding on flowers indirectly block pollination and the production of seeds by destroying the corolla or the stigma, which receives the pollen grains and on which the pollen germinates. Without their colorful corolla, flowers do not attract pollinators and are not fertilized. An adult grasshopper can consume a large corolla, about 2.5 inches long, in an hour. Caterpillars and seed beetles affect seed production directly. Caterpillars devour the ovaries, where the seeds are produced, and seed beetle larvae eat seeds as they burrow in developing fruits.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Extrafloral nectaries at the base of each sepal attract several kinds of insects, but 96 percent of them are ants, several different species of them. When buds are still small, less than a quarter of an inch long, the sepal nectaries are already present and producing</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">nectar. They continue to do so as the flower develops and while the fruit matures. Observations leave little doubt that ants protect morning glory flowers and fruits from the combined enemy force of grasshoppers, caterpillars, and seed beetles. Bentley compared the seed production of six plants that grew where there were no ants with that of seventeen plants that were occupied by ants. Unprotected plants bore only 45 seeds per plant, but plants occupied by ants bore 211 seeds per plant. Although ants are not big enough to kill or seriously injure grasshoppers, they drive them away by nipping at their  feet.  Seed  beetles  are  more  vulnerable  because they  are much  smaller  than grasshoppers. The ants prey on the adult beetles, disturb females as they lay their eggs on developing fruits, and eat many of the eggs they do manage to lay.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> ISLAMIC ART AND THE BOOK                                                                               </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">The arts of the Islamic book, such as calligraphy and decorative drawing, developed during A.D. 900 to 1500, and luxury books are some of the most characteristic examples of Islamic art produced in this period. This came about from two major developments: paper became common, replacing parchment as the major medium for writing, and rounded scripts were regularized and perfected so that they replaced the angular scripts of the previous period, which because of their angularity were uneven in height.Books became major vehicles for artistic expression, and the artists who produced them, notably calligraphers and painters, enjoyed high status, and their workshops were often sponsored by princes and their courts. Before A.D. 900, manuscripts of the Koran (the book containing the teachings of the Islamic religion) seem to have been the most common type of book produced and decorated, but after that date a wide range of books were produced for a broad spectrum of patrons. These continued to include, of course, manuscripts of the Koran, which every Muslim wanted to read, but scientific works, histories, romances, and epic and lyric poetry were also copied in fine handwriting and decorated with beautiful illustrations. Most were made for sale on the open market, and cities boasted special souks (markets) where books were bought and sold. The mosque of Marrakech in Morocco is known as the Kutubiyya, or Booksellers’ Mosque, after the adjacent market. Some of the most luxurious books were specific commissions made at the order of a particular prince and signed by the calligrapher and decorator.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Papermaking had been introduced to the Islamic lands from China in the eighth century. It has been said that Chinese papermakers were among the prisoners captured in a battle fought near Samarqand between the Chinese and the Muslims in 751, and the technique of papermaking—in which cellulose pulp extracted from any of several plants is first suspended in water, caught on a fine screen, and then dried into flexible sheets— slowly spread westward. Within fifty years, the government in Baghdad was using paper for documents. Writing in ink on paper, unlike parchment, could not easily be erased, and therefore paper had the advantage that it was difficult to alter what was written on it. Papermaking spread quickly to Egypt—and eventually to Sicily and Spain—but it was several centuries before paper supplanted parchment for copies of the Koran,</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">probably because of the conservative nature of religious art and its practitioners. In western Islamic lands, parchment continued to be used for manuscripts of the Koran throughout this period.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The introduction of paper spurred a conceptual revolution whose consequences have barely been explored. Although paper was never as cheap as it has become today, it was far less expensive than parchment, and therefore more people could afford to buy books. Paper is thinner than parchment, so more pages could be enclosed within a single volume. At first, paper was made in relatively small sheets that were pasted together, but by the beginning of the fourteenth century, very large sheets—as much as a meter across—were available. These large sheets meant that calligraphers and artists had more space on which to work. Paintings became more complicated, giving the artist greater opportunities to depict space or emotion. The increased availability of paper, particularly after 1250, encouraged people to develop systems of representation, such as architectural plans and drawings. This in turn allowed the easy transfer of artistic ideas and motifs over great distances, from one medium to another, and in a different scale in ways that had been difficult, if not impossible, in the previous period.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Rounded styles of Arabic handwriting had long been used for correspondence and documents alongside the formal angular scripts used for inscriptions and manuscripts of the Koran. Around the year 900, Ibn Muqla, who was a secretary and vizier at the Abbasid court in Baghdad, developed a system of proportioned writing. He standardized the length of alif, the first letter of the Arabic alphabet, and then determined what the size and shape of all other letters should be, based on the alif. Eventually, six round forms of handwriting, composed of three pairs of big and little scripts known collectively as the Six Pens, became the standard repertory of every calligrapher.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;">  THE DEVELOPMENT OF STEAM POWER                                                            </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">By the eighteenth century, Britain was experiencing a severe shortage of energy. Because of the growth of population, most of the great forests of medieval Britain had long ago been replaced by fields of grain and hay. Wood was in ever-shorter supply, yet it remained tremendously important. It served as the primary source of heat for all homes and industries and as a basic raw material. Processed wood (charcoal) was the fuel that was mixed with iron ore in the blast furnace to produce pig iron (raw iron). The iron industry’s appetite for wood was enormous, and by 1740 the British iron industry was stagnating. Vast forests enabled Russia to become the world’s leading producer of iron, much of which was exported to Britain. But Russia’s potential for growth was limited too, and in a few decades Russia would reach the barrier of inadequate energy that was already holding England back.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">As this early energy crisis grew worse, Britain looked toward its abundant and widely scattered reserves of coal as an alternative to its vanishing wood. Coal was first used in Britain in the late Middle Ages as a source of heat. By 1640 most homes in</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">London were heated with it, and it also provided heat for making beer, glass, soap, and other products. Coal was not used, however, to produce mechanical energy or to power machinery. It was there that coal’s potential was enormous.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">As more coal was produced, mines were dug deeper and deeper and were constantly filling with water. Mechanical pumps, usually powered by hundreds of horses walking in circles at the surface, had to be installed. Such power was expensive and bothersome. In an attempt to overcome these disadvantages, Thomas Savery in 1698 and Thomas Newcomen in 1705 invented the first primitive steam engines. Both engines were extremely inefficient. Both burned coal to produce steam, which was then used to operate a pump. However, by the early 1770s, many of the Savery engines and hundreds of the Newcomen engines were operating successfully, though inefficiently, in English and Scottish mines.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In the early 1760s, a gifted young Scot named James Watt was drawn to a critical study of the steam engine. Watt was employed at the time by the University of Glasgow as a skilled crafts worker making scientific instruments. In 1763, Watt was called on to repair a Newcomen engine being used in a physics course. After a series of observations, Watt saw that the Newcomen’s waste of energy could be reduced by adding a separate condenser. This splendid invention, patented in 1769, greatly increased the efficiency of the steam engine. The steam engine of Watt and his followers was the technological advance that gave people, at least for a while, unlimited power and allowed the invention and use of all kinds of power equipment.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The steam engine was quickly put to use in several industries in Britain. It drained mines and made possible the production of ever more coal to feed steam engines elsewhere. The steam power plant began to replace waterpower in the cotton-spinning mills as well as other industries during the 1780s, contributing to a phenomenal rise in industrialization.  The  British  iron industry  was radically  transformed.  The use  of powerful, steam-driven bellows in blast furnaces helped iron makers switch over rapidly from limited charcoal to unlimited coke (which is made from coal) in the smelting of pig iron (the process of refining impure iron) after 1770. In the 1780s, Henry Cort developed the puddling furnace, which allowed pig iron to be refined in turn with coke. Cort also developed heavy-duty, steam-powered rolling mills, which were capable of producing finished iron in every shape and form.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The economic consequence of these technical innovations in steam power was a great boom in the British iron industry. In 1740 annual British iron production was only 17,000 tons, but by 1844, with the spread of coke smelting and the impact of Cort’s inventions, it had increased to 3,000,000 tons. This was a truly amazing expansion. Once scarce and expensive, iron became cheap, basic, and indispensable to the economy.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">SEASONAL SUCCESSION IN PHYTOPLANKTON</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO35</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Phytoplankton are  minute, free-floating aquatic plants. In addition  to the marked changes in abundance observed in phytoplankton over the course of a year, there is also a marked change in species composition. This change in the dominant species from season to season is called seasonal succession, and it occurs in a wide variety of locations. Under seasonal succession, one or more species dominate the phytoplankton for a shorter or longer period of time and then are replaced by another set of species. This pattern is repeated yearly. This succession is different from typical terrestrial ecological succession in which various plants replace one another until finally a so- called climax community develops, which persists for many years.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">What are the factors causing this phenomenon? Considering that seasonal succession is most often and clearly seen in temperate seas, which have a marked change in temperature during a year, temperature has been suggested as a cause. This may be one of the factors, but it is unlikely to be the sole cause because there are species that become dominant species at various temperatures. Furthermore, temperature changes rather slowly in seawater, and the replacement of dominant species often is much more rapid.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Another suggested reason is the change in nutrient level over the year, with differing concentrations favoring different phytoplankton species. While this factor may also contribute, observations suggest that phytoplankton populations rise and fall much more quickly than nutrient concentrations change.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Yet another explanation is that species succession is a consequence of changes in seawater brought about by the phytoplankton living in it. Each species of phytoplankton secretes or excretes organic molecules into the seawater. These metabolites can have an effect on the organisms living in the seawater, either inhibiting or promoting their growth. For any individual organism, the amount of metabolite secreted is small. But the effect of secretions by all the individuals of the dominant species can be significant both for themselves and for other species.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">These organic metabolites could, and probably do, include a number of different classes of organic compounds. Some are likely toxins, such as those released by the dinoflagellates (a species of plankton) during red tides, which inhibit growth of other photosynthetic organisms. In such cases, the population explosion of dinoflagellates is so great that the water becomes brownish red in color from the billions of dinoflagellate cells. Although each cell secretes a minute amount of toxin, the massive dinoflagellate numbers cause the toxin to reach concentrations that kill many creatures. This toxin can</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">be concentrated in such filter-feeding organisms as clams and mussels, rendering them toxic to humans.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Another class of metabolite is the vitamins. It is now known that certain phytoplankton species have requirements for certain vitamins, and that there are considerable differences among species as to requirements. The B vitamins, especially vitamin B12, thiamine, and biotin, seem to be the most generally required. Some species may be unable to thrive until a particular vitamin, or group of vitamins, is present in the water. These vitamins are produced only by another species; hence, a succession of species could occur whereby first the vitamin-producing species is present and then the vitamin-requiring species follows.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Other organic compounds that may inhibit or promote various species include amino acids, carbohydrates, and fatty acids. Although it is suspected that these organic metabolites may have an important role in species succession and it has been demonstrated in the laboratory that phytoplankton species vary both in their ability to produce necessary vitamins and in their requirements for such in order to grow, evidence is still inadequate as to their real role in the sea.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">There is also evidence to suggest that grazers (animals that feed on plants or stationary animals),particularly selective grazers, can influence the phytoplankton species composition. Many copepods (small, herbivorous crustaceans) and invertebrate larvae pick out selected phytoplankton species from mixed groups, changing the species composition.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">A growing body of evidence now suggests that all of the factors considered here are operating simultaneously to produce species succession. The importance of any factor will vary with the particular phytoplankton species and the environmental conditions.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;">  THE DEVELOPMENT OF SOCIAL COMPLEXITY                                              </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">For most of human history, we have foraged (hunted, fished, and collected wild plants) for food. Small nomadic groups could easily supply the necessities for their families. No one needed more, and providing for more than one’s needs made little sense. The organization of such societies could be rather simple, revolving around age and gender categories. Such societies likely were largely egalitarian; beyond distinctions based on age and gender, virtually all people had equivalent rights, status, and access to resources.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Archaeologist Donald Henry suggests that the combination of a rich habitat and sedentism (permanent, year-round settlement) led to a dramatic increase in human population. In his view, nomadic, simple foragers have relatively low levels of fertility. Their high-protein, low-carbohydrate diets result in low body-fat levels, which are commonly associated with low fertility in women. High levels of physical activity and</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">long periods of nursing, which are common among modern simple foragers, probably also contributed to low levels of female fertility if they were likewise common among ancient foragers.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In Henry’s view, the adoption of a more settled existence in areas with abundant food resources would have contributed to higher fertility levels among the sedentary foragers. A diet higher in wild cereals produces proportionally more body fat, leading to higher fertility among women. Cereals, which are easy to digest, would have supplemented and then replaced mother’s milk as the primary food for older infants. Since women are less fertile when they are breast-feeding, substituting cereals for mother’s milk would have resulted in closer spacing of births and the potential for a greater number of live births for each woman. A more sedentary existence may also have lowered infant mortality and perhaps increased longevity among the aged. These more vulnerable members of society could safely stay in a fixed village rather than be forced regularly to move great distances as part of a nomadic existence, with its greater risk of accidents and trauma.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">All of these factors may have resulted in a trend of increasing size among some local human populations in the Holocene (since 9600 B.C.E.). Given sufficient time, even in very rich habitats, human population size can reach carrying capacity, the maximum population an area can sustain within the context of a given subsistence system. And human population growth is like a runaway train: once it picks up speed, it is difficult to control. So even after reaching an area’s carrying capacity, Holocene human populations probably continued to grow in food-rich regions, overshooting the ability of the territory to feed the population, again within the context of the same subsistence strategy. In some areas, small changes in climate or minor changes in plant characteristics may have further destabilized local economies.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One possible response to surpassing the carrying capacity of a region is for a group to exploit adjoining land. However, good land may itself be limited—for example, to within the confines of a river valley.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Where neighbors are in the same position, having filled up the whole of the desirable habitat available in their home territories, expansion is also problematic. Impinging on the neighbors’ territory can lead to conflict, especially when they too are up against the capacity of the land to provide enough food.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Another option is to stay in the same area but to shift and intensify the food quest there. The impulse to produce more food to feed a growing population was satisfied in some areas by the development of more-complex subsistence strategies involving intensive labor and requiring more cooperation and greater coordination among the increasing numbers of people. This development resulted in a change in the social and economic equations that defined those societies. Hierarchies that did not exist in earlier</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">foraging groups but that were helpful in structuring cooperative labor and in organizing more-complex technologies probably became established, even before domestication and agriculture, as pre-Neolithic societies (before the tenth millennium B.C.E.) reacted to the population increase.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> EARTH&#39;S AGE                                                                                                                 </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">One of the first recorded observers to surmise a long age for Earth was the Greek historian Herodotus, who lived from approximately 480 B.C. to 425 B.C. He observed that the Nile River Delta was in fact a series of sediment deposits built up in successive floods. By noting that individual floods deposit only thin layers of sediment, he was able to conclude that the Nile Delta had taken many thousands of years to build up. More important than the amount of time Herodotus computed, which turns out to be trivial compared with the age of Earth, was the notion that one could estimate ages of geologic features by determining rates of the processes responsible for such features, and then assuming the rates to be roughly constant over time. Similar applications of this concept were to be used again and again in later centuries to estimate the ages of rock formations and, in particular, of layers of sediment that had compacted and cemented to form sedimentary rocks.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">It was not until the seventeenth century that attempts were made again to understand clues to Earth’s history through the rock record. Nicolaus Steno (1638–1686) was the first to work out principles of the progressive depositing of sediment in Tuscany. However, James Hutton (1726–1797), known as the founder of modern geology, was the first to have the important insight that geologic processes are cyclic in nature. Forces associated with subterranean heat cause land to be uplifted into plateaus and mountain ranges. The effects of wind and water then break down the masses of uplifted rock, producing sediment that is transported by water downward to ultimately form layers in lakes, seashores, or even oceans. Over time, the layers become sedimentary rock. These rocks are then uplifted sometime in the future to form new mountain ranges, which exhibit the sedimentary layers (and the remains of life within those layers) of the earlier episodes of erosion and deposition.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Hutton’s concept represented a remarkable insight because it unified many individual phenomena and observations into a conceptual picture of Earth’s history. With the further assumption that these geologic processes were generally no more or less vigorous than they are today, Hutton’s examination of sedimentary layers led him to realize that Earth’s history must be enormous, that geologic time is an abyss and human history a speck by comparison.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">After Hutton, geologists tried to determine rates of sedimentation so as to estimate the age of Earth from the total length of the sedimentary, or stratigraphic, record. Typical numbers produced at the turn of the twentieth century were 100 million to 400 million</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">years. These underestimated the actual age by factors of 10 to 50 because much of the sedimentary record is missing in various locations and because there is a long rock sequence that is older than half a billion years that is far less well defined in terms of fossils and less well preserved.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Various other techniques to estimate Earth’s age fell short, and particularly noteworthy in this regard were flawed determinations of the Sun’s age. It had been recognized by the German philosopher Immanuel Kant (1724–1804) that chemical reactions could not supply the tremendous amount of energy flowing from the Sun for more than about a millennium. Two physicists during the nineteenth century both came up with ages for the Sun based on the Sun’s energy coming from gravitational contraction.Under the force of gravity, the compression resulting from a collapse of the object must release energy. Ages for Earth were derived that were in the tens of millions of years, much less than the geologic estimates of the time.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">SOIL FORMATION</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO36</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">It was the discovery of radioactivity at the end of the nineteenth century that opened the door to determining both the Sun’s energy source and the age of Earth. From the initial work came a suite of discoveries leading to radioisotopic dating, which quickly led to the realization that Earth must be billions of years old, and to the discovery of nuclear fusion as an energy source capable of sustaining the Sun’s luminosity for that amount of time. By the 1960s, both analysis of meteorites and refinements of solar evolution models converged on an age for the solar system, and hence for Earth, of 4.5 billion years.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Living organisms play an essential role in soil formation. The numerous plants and animals living in the soil release minerals from the parent material from which soil is formed, supply organic matter, aid in the translocation (movement) and aeration of the soil, and help protect the soil from erosion. The types of organisms growing or living in the soil greatly influence the soil’s physical and chemical characteristics. In fact, for mature soils in many parts of the world, the predominant type of natural vegetation is considered the most important direct influence on soil characteristics. For this reason, a soil scientist can tell a great deal about the attributes of the soil in any given area simply from knowing what kind of flora the soil supports. Thus prairies and tundra regions, which have characteristic vegetations, also have characteristic soils.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The quantity and total weight of soil flora generally exceed that of soil fauna. By far the most numerous and smallest of the plants living in soil are bacteria. Under favorable conditions, a million or more of these tiny, single-celled plants can inhabit each cubic centimeter of soil. It is the bacteria, more than any other organisms, that enable rock or other parent material to undergo the gradual transformation to soil. Some bacteria</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">produce organic acids that directly attack parent material, breaking it down and releasing plant nutrients. Others decompose organic litter (debris) to form humus (nutrient-rich organic matter). A third group of bacteria inhabits the root systems of plants called legumes. These include many important agricultural crops, such as alfalfa, clover, soybeans, peas, and peanuts. The bacteria that legumes host within their root nodules (small swellings on the root) change nitrogen gas from the atmosphere into nitrogen compounds that plants are able to metabolize, a process, known as nitrogen fixation, that makes the soil more fertile. Other microscopic plants also are important in soil development. For example, in highly acidic soils where few bacteria can survive, fungi frequently become the chief decomposers of organic matter.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">More complex forms of vegetation play several vital roles with respect to the soil. Trees, grass, and other large plants supply the bulk of the soil’s humus. The minerals released as these plants decompose on the surface constitute an important nutrient source for succeeding generations of plants as well as for other soil organisms. In addition, trees can extend their roots deep within the soil and bring up nutrients from far below the surface. These nutrients eventually enrich the surface soil when the tree drops its leaves or when it dies and decomposes. Finally, trees perform the vital function of slowing  water runoff  and  holding  the soil  in  place with  their  root  systems, thus combating erosion. The increased erosion that often accompanies agricultural use of sloping land is principally caused by the removal of its protective cover of natural vegetation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Animals also influence soil composition. The faunal counterparts of bacteria are protozoa. These single-celled organisms are the most numerous representatives of the animal kingdom, and, like bacteria, a million or more can sometimes inhabit each cubic centimeter of soil. Protozoa feed on organic matter and hasten its decomposition. Among other soil-dwelling animals, the earthworm is probably the most important. Under exceptionally favorable conditions, up to a million earthworms (with a total body weight exceeding 450 kilograms) may inhabit an acre of soil. Earthworms ingest large quantities of soil, chemically alter it, and excrete it as organic matter called casts. The casts form a high-quality natural fertilizer. In addition, earthworms mix soil both vertically and horizontally, improving aeration and drainage.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Insects such as ants and termites also can be exceedingly numerous under favorable climatic and soil conditions. In addition, mammals such as moles, field mice, gophers, and prairie dogs sometimes are present in sufficient numbers to have significant impact on the soil. These animals primarily work the soil mechanically. As a result, the soil is aerated, broken up, fertilized, and brought to the surface, hastening soil development.</p><p style="padding-top: 3pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> EARLY IDEAS ABOUT DEEP-SEA BIOLOGY                                                      </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">In 1841 Edward Forbes was offered the chance to serve as naturalist aboard HMS Beacon, an English Royal Navy ship assigned to survey the Aegean Sea. For a year and a half the Beacon crisscrossed the Aegean waters. During that time Forbes was able to drag his small, triangular dredge—a tool with a leather net for capturing creatures along the sea bottom—at a hundred locations, at depths ranging from 6 to 1,380 feet. He collected hundreds of different species of animals, and he saw that they were distributed in eight different depth zones, each containing its own distinct assemblage of animal life, the way zones of elevation on the side of a mountain are populated by distinct sets of plants.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Forbes also thought he saw, as he later told the British Association, that “the number of species and individuals diminishes as we descend, pointing to a zero in the distribution of animal life as yet unvisited.” This zero, Forbes casually speculated—he simply extended a line on his graph of animal number versus depth—probably began at a depth of 1,800 feet. Below that was the final zone in Forbes’s scheme, zone nine, a zone that covered most of the ocean floor and thus most of the solid surface of Earth: Forbes called this the azoic zone, where no animal, to say nothing of plants, could survive.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: left;">Forbes’s azoic zone was entirely plausible at the time, and it was certainly far from the strangest idea that was then entertained about the deep sea. In the first decade of the nineteenth century, a French naturalist named François Péron had sailed around the world measuring the temperature of the ocean. He found that the deeper the water, the colder it got, and he concluded that the seafloor was covered with a thick layer of ice. Péron ignored the fact that water expands when it freezes and that ice therefore floats. A more popular belief at the time was that water at great depth would be compressed to such a density that nothing could sink through it. This ignored the fact that water is all but incompressible. But even the more sensible naturalists of the day were guilty of a similar misconception. They imagined the deep sea as being filled with an unmoving and undisturbable pool of cold, dense water. In reality the deep is always being refreshed by cold water sinking from above.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The central implication of all these misconceptions was that nothing could live in the abyss (deep), just as Forbes’s observations seemed to indicate. But Forbes erred in two ways. One was the particular study site he happened to use as a springboard for his sweeping postulate of a lifeless abyss. Although the Aegean had been the birthplace of marine biology, its depths are now known to be exceptionally lacking in animal diversity. Moreover, through no fault of his own, Forbes was not particularly successful at sampling such life as did exist at the bottom of the Aegean. It was his dredge that was inadequate. Its opening was so small and the holes in the net so large that the dredge inevitably missed animals. Many of those it did catch must have poured out of its open</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">mouth when Forbes reeled it in. His azoic zone, then, was a plausible but wild extrapolation from pioneering but feeble data.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">As it turned out, the existence of the azoic zone had been disproved even before Forbes suggested it, and the theory continued to be contradicted regularly throughout its long and influential life. Searching for the Northwest Passage from the Atlantic to the Pacific in 1818, Sir John Ross had lowered his “deep-sea clam”—a sort of bivalved sediment scoop—into the waters of Baffin Bay (an inlet between the Atlantic and Arctic oceans), which he determined to be more than a thousand fathoms deep in some places. Modern soundings indicate he overestimated his depths by several hundred fathoms, but in any case Ross’s clam dove several times deeper than Forbes’s dredge. It brought back mud laced with worms, and starfish that had entangled themselves in the line at depths well below the supposed boundary of the azoic zone.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> INDUSTRIAL MELANISM: THE CASE OF THE PEPPERED MOTH               </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">The idea of natural selection is that organisms in a species that have characteristics favoring survival are most likely to survive and produce offspring with the same characteristics. Because the survival of organisms with particular characteristics is favored over the survival of other organisms in the same species that lack these characteristics, future generations of the species are likely to include more organisms with the favorable characteristics.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One of the most thoroughly analyzed examples of natural selection in operation is the change in color that has occurred in certain populations of the peppered moth, Biston betularia, in industrial regions of Europe during the past 100 years. Originally moths were uniformly pale gray or whitish in color; dark-colored (melanic) individuals were rare and made up less than 2 percent of the population. Over a period of decades, dark- colored forms became an increasingly large fraction of some populations and eventually came to dominate peppered moth populations in certain areas—especially those of extreme industrialization such as the Ruhr Valley of Germany and the Midlands of England. Coal from industry released large amounts of black soot into the environment, but the increase of the dark-colored forms was not due to genetic mutations caused by industrial pollution. For example, caterpillars that feed on soot-covered leaves did not give rise to dark-colored adults. Rather, pollution promoted the survival of dark forms on soot-covered trees. Melanics were normally quickly eliminated in nonindustrial areas by adverse selection; birds spotted them easily. This phenomenon, an increase in the frequency of dark-colored mutants in polluted areas, is known as industrial melanism. The North American equivalent of this story is another moth, the swettaria form of Biston cognataria, first noticed in industrialized areas such as Chicago and New York City in the early 1900s. By 1961 it constituted over 90 percent of the population in parts of Michigan.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">The idea that natural selection was responsible for the changing ratio of dark- to light-colored peppered moths was developed in the 1950s by H. B. D. Kettlewell of Oxford University. If natural selection was the explanation, then there should be different survival rates for dark- and light-colored moths. To determine whether this was true, Kettlewell released thousands of light and dark moths (each marked with a paint spot) into rural and industrialized areas. In the nonindustrial area of Dorset, he recaptured 14.6 percent of the pale forms but only 4.7 percent of the dark forms. In the industrial area of Birmingham, the situation was reversed: 13 percent of pale forms but</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">27.5 percent of dark forms were recaptured.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Clearly some environmental factor was responsible for the greater survival rates of dark moths. Birds were predators of peppered moths. Kettlewell hypothesized that the normal pale forms are difficult to see when resting on lichen-covered trees, whereas dark forms are conspicuous. In industrialized areas, lichens are destroyed by pollution, tree barks become darker, and dark moths are the ones birds have difficulty detecting. As a test, Kettlewell set up hidden observation positions and watched birds voraciously eat moths placed on tree trunks of a contrasting color. The action of natural selection in producing a small but highly significant step of evolution was seemingly demonstrated, with birds as the selecting force.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Not every researcher has been convinced that natural selection by birds is the only explanation of the observed frequencies of dark and light peppered moths. More recent data, however, provide additional support for Kettlewell’s ideas about natural selection. The light-colored form of the peppered moth is making a strong comeback. In Britain, a Clean Air Act was passed in 1965. Sir Cyril Clarke has been trapping moths at his home in Liverpool, Merseyside, since 1959. Before about 1975, 90 percent of the moths were dark, but since then there has been a steep decline in melanic forms, and in 1989 only 29.6 percent of the moths caught were melanic. The mean concentration of sulphur dioxide pollution fell from about 300 micrograms per cubic meter in 1970 to less than 50 micrograms per cubic meter in 1975 and has remained fairly constant since then. If the spread of the light-colored form of the moth continues at the same speed as the melanic form spread in the last century, soon the melanic form will again be only an occasional resident of the Liverpool area.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">THALES AND THE MILESIANS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO37</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">While many other observers and thinkers had laid the groundwork for science, Thales (circa 624 B.C.E.–ca 547 B.C.E.), the best known of the earliest Greek philosophers, made the first steps toward a new, more objective approach to finding out about the world. He posed a very basic question: “What is the world made of?” Many others had asked the same question before him, but Thales based his answer strictly on what he had</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">observed and what he could reason out—not on imaginative stories about the gods or the supernatural. He proposed water as the single substance from which everything in the world was made and developed a model of the universe with Earth as a flat disk floating in water.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Like most of the great Greek philosophers, Thales had an influence on others around him. His two best-known followers, though there were undoubtedly others who attained less renown, were Anaximander and Anaximenes. Both were also from Miletus (located on the southern coast of present-day Turkey) and so, like Thales, were members of the Milesian School. Much more is known about Anaximander than about Anaximenes, probably because Anaximander, who was born sometime around 610 BCE, ambitiously attempted to write a comprehensive history of the universe. As would later happen between another teacher-student pair of philosophers, Plato and Aristotle, Anaximander disagreed with his teacher despite his respect for him. He doubted that the world and all its contents could be made of water and proposed instead a formless and unobservable substance he called “apeiron” that was the source of all matter.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Anaximander’s most important contributions, though, were in other areas. Although he did not accept that water was the prime element, he did believe that all life originated in the sea, and he was thus one of the first to conceive of this important idea. Anaximander is credited with drawing up the first world map of the Greeks and also with recognizing that Earth’s surface was curved. He believed, though, that the shape of Earth was that of a cylinder rather than the sphere that later Greek philosophers would conjecture. Anaximander, observing the motions of the heavens around the polestar, was probably the first of the Greek philosophers to picture the sky as a sphere completely surrounding Earth—an idea that, elaborated upon later, would prevail until the advent of the Scientific Revolution in the seventeenth century.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Unfortunately, most of Anaximander’s written history of the universe was lost, and only a few fragments survive today. Little is known about his other ideas. Unfortunately, too, most of the written work of Anaximenes, who may have been Anaximander’s pupil, has also been lost. All we can say for certain about Anaximenes, who was probably born around 560 BCE, is that following in the tradition of Anaximander, he also disagreed with his mentor. The world, according to Anaximenes, was not composed of either water or apeiron, but air itself was the fundamental element of the universe. Compressed, it became water and earth, and when rarefied or thinned out, it heated up to become fire. Anaximenes may have also been the first to study rainbows and speculate upon their natural rather than supernatural cause.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">With the door opened by Thales and the other early philosophers of Miletus, Greek thinkers began to speculate about the nature of the universe. This exciting burst of intellectual activity was for the most part purely creative. The Greeks, from Thales to Plato and Aristotle, were philosophers and not scientists in today’s sense. It is possible</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">for anyone to create “ideas” about the nature and structure of the universe, for instance, and many times these ideas can be so consistent and elaborately structured, or just so apparently obvious, that they can be persuasive to many people. A scientific theory about the universe, however, demands much more than the various observations and analogies that were woven together to form systems of reasoning, carefully constructed as they were, that would eventually culminate in Aristotle’s model of the world and the universe. Without experimentation and objective, critical testing of their theories, the best these thinkers could hope to achieve was some internally consistent speculation that covered all the bases and satisfied the demands of reason.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> DIRECT SPECIES TRANSLOCATION                                                                     </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">It is becoming increasingly common for conservationists to move individual animals or entire species from one site to another. This may be either to establish a new population where a population of conspecifics (animals or plants belonging to the same species) has become extinct or to add individuals to an existing population. The former is termed reintroduction and the latter reinforcement. In both cases, wild individuals are captured in one location and translocated directly to another.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Direct translocation has been used on a wide range of plants and animals and was carried out to maintain populations as a source of food long before conservation was a familiar term. The number of translocations carried out under the banner of conservation has increased rapidly, and this has led to criticism of the technique because of the lack of evaluation of its efficacy and because of its potential disadvantages. The nature of translocation ranges from highly organized and researched national or international programs to ad hoc releases of rescued animals by well-intentioned animal lovers. In a fragmented landscape where many populations and habitats are isolated from others, translocations can play an effective role in conservation strategies; they can increase the number of existing populations or increase the size, genetic diversity, and demographic balance of a small population, consequently increasing its chances of survival.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Translocation clearly has a role in the recovery of species that have substantially declined and is the most likely method by which many sedentary species can recover all or part of their former range. However, against this is the potential for reinforcement translocations to spread disease from one population to another or to introduce deleterious or maladaptive genes to a population. Additionally, translocation of predators or competitors may have negative impacts on other species, resulting in an overall loss of diversity. Last but not least of these considerations is the effort and resources required in this type of action, which need to be justified by evidence of the likely benefits.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Despite the large number of translocations that have taken place, there is surprisingly little evidence of the efficacy of such actions. This is partly because many</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">translocations have not been strictly for conservation; neither have they been official nor legal, let alone scientific in their approach. Successful translocations inevitably get recorded and gain attention, whereas failures may never be recorded at all. This makes appraisal of the method very difficult. One key problem is a definition of success. Is translocation successful if the individuals survive the first week or a year, or do they need to reproduce for one or several generations? Whatever the answer, it is clear that a general framework is required to ensure that any translocation is justified, has a realistic chance of success, and will be properly monitored and evaluated for the benefit of future efforts.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">An example of apparent translocation success involves the threatened Seychelles warbler. This species was once confined to Cousin Island, one of the Seychelles islands, and reduced to 26 individuals. Careful habitat management increased this number to over 300 birds, but the single population remained vulnerable to local catastrophic events. The decision was taken to translocate individuals to two nearby islands to reduce this risk. The translocations took place in 1988 and 1990, and both have resulted in healthy breeding populations. A successful translocation exercise also appears to have been achieved with red howler monkeys in French Guiana. A howler population was translocated from a site due to be flooded for hydroelectric power generation. The release site was an area where local hunting had reduced the density of the resident howler population. Released troops of monkeys were kept under visual observation and followed by radio tracking of 16 females. Although the troops appeared to undergo initial problems, causing them to split up, all the tracked females settled into normal behavioral patterns.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Unfortunately, the success stories are at least matched by accounts of failure. Reviewing translocation of amphibians and reptiles, researchers C. Kenneth Dodd and Richard A. Siegel concluded that most projects have not demonstrated success as conservation techniques and should not be advocated as though they were acceptable management and mitigation practices.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> MODERN ARCHITECTURE IN THE UNITED STATES                                      </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">At the end of the nineteenth century, there were basically two kinds of buildings in the United States. On one hand were the buildings produced for the wealthy or for civic purposes, which tended to echo the architecture of the past and to use traditional styles of ornamentation. On the other hand were purely utilitarian structures, such as factories and grain elevators, which employed modern materials such as steel girders and plate glass in an undisguised and unadorned manner. Such buildings, however, were viewed in a category separate from “fine” architecture, and in fact were often designed by engineers and builders rather than architects. The development of modern architecture might in large part be seen as an adaptation of this sort of functional building and its pervasive application for daily use. Indeed, in his influential book Toward a New</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Architecture, the Swiss architect Le Corbusier illustrated his text with photographs of American factories and grain storage silos, as well as ships, airplanes, and other industrial objects. Nonetheless, modern architects did not simply employ these new materials in a strictly practical fashion—they consciously exploited their aesthetic possibilities. For example, glass could be used to open up walls and eliminate their stone and brick masonry because large spaces could now be spanned with steel beams.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The fundamental premise of modern architecture was that the appearance of the building should exhibit the nature of its materials and forms of physical support. This often led to effects that looked odd from a traditional standpoint but that became hallmarks of modern architecture for precisely this reason. For example, in traditional architecture, stone or brick walls served a structural role, but in a steel-beam building the walls were essentially hung from the internal skeleton of steel beams, which meant that walls and corners no longer needed to be solid but could be opened up in unexpected ways. At the Fagus shoe factory in Germany, for example, German architect Walter Gropius placed glass walls in the corners, effectively breaking open the box of traditional architecture and creating a new sense of light and openness. Similarly, steel beams could be used to construct balconies that projected out from the building without any support beneath them. These dramatic balconies quickly became a signature of modern architects such as Frank Lloyd Wright. Wright’s most dramatic residence, Fallingwater, has balconies that thrust far out over a stream in a way that seems to defy gravity.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The ways in  which new technology transformed architectural design are dramatically illustrated through the evolution of the high-rise office building. After ten or twelve stories, masonry construction reaches a maximum possible height, since it runs into difficulties of compression and of inadequate lateral strength to combat wind shear. Steel construction, on the other hand, can support a building of 50 or 100 stories without difficulty. Such buildings were so different from any previous form of architecture that they quickly acquired a new name—the skyscraper.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">From the standpoint of real estate developers, the purpose of skyscrapers was to increase rental space in valuable urban locations. But to create usable high-rise buildings, a number of technical challenges needed to be solved. One problem was getting people to the upper floors, since after five or six stories it becomes exhausting to climb stairs. Updated and electrified versions of the freight elevator that had been introduced by Elish Graves Otis  in  1853  (several  decades before  skyscraper  construction)  solved this problem. Another issue was fire safety. The metal supporting buildings became soft when exposed to fire and collapsed relatively quickly. (They could melt at 2,700 Fahrenheit, whereas major fires achieve temperatures of 3,000 degrees). However, when the metal is encased in fire-retardant materials, its vulnerability to fire is much decreased. In Chicago, a system was developed for surrounding the metal components with hollow tiles made from brick-like terra-cotta. Such tiles are impervious to fire. The terra-cotta</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">tiles were used both to encase the supporting members and as flooring. A structure built with steel beams protected by terra-cotta tiles was still three times lighter than a comparably sized building that used masonry construction, so the weight of the tiles was not a problem.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">MICROSCOPES</p><p style="text-indent: 0pt;text-align: left;"/><p class="s1" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">TPO38</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Before microscopes were first used in the seventeenth century, no one knew that living organisms were composed of cells. The first microscopes were light microscopes, which work by passing visible light through a specimen. Glass lenses in the microscope bend the light to magnify the image of the specimen and project the image into the viewer’s eye or onto photographic film. Light microscopes can magnify objects up to 1,000 times without causing blurriness.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Magnification, the increase in the apparent size of an object, is one important factor in microscopy. Also important is resolving power, a measure of the clarity of an image. Resolving power is the ability of an optical instrument to show two objects as separate. For example, what looks to the unaided eye like a single star in the sky may be resolved as two stars with the help of a telescope. Any optical device is limited by its resolving power. The light microscope cannot resolve detail finer than 0.2 micrometers, about the size of the smallest bacterium; consequently, no matter how many times its image of such a bacterium is magnified, the light microscope cannot show the details of the cell’s internal structure.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">From the year 1665, when English microscopist Robert Hooke discovered cells, until the middle of the twentieth century, biologists had only light microscopes for viewing cells. But they discovered a great deal, including the cells composing animal and plant tissues, microscopic organisms, and some of the structures within cells. By the mid-1800s, these discoveries led to the cell theory, which states that all living things are composed of cells and that all cells come from other cells.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Our knowledge of cell structure took a giant leap forward as biologists began using the electron microscope in the 1950s. Instead of light, the electron microscope uses a beam of electrons and has a much higher resolving power than the light microscope. In fact, the most powerful modern electron microscopes can distinguish objects as small as 0.2 nanometers, a thousandfold improvement over the light microscope. The period at the end of this sentence is about a million times bigger than an object 0.2 nanometers in diameter, which is the size of a large atom. Only under special conditions can electron microscopes detect individual atoms. However, cells, cellular organelles, and even molecules like DNA and protein are much larger than single atoms.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Biologists use the scanning electron microscope to study the detailed architecture of cell surfaces. It uses an electron beam to scan the surface of a cell or group of cells that have been coated with metal. The metal stops the beam from going through the cells. When the metal is hit by the beam, it emits electrons. The electrons are focused to form an image of the outside of the cells. The scanning electron microscope produces images that look three-dimensional.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The transmission electron microscope, on the other hand, is used to study the details of internal cell structure. Specimens are cut into extremely thin sections, and the transmission electron microscope aims an electron beam through a section, just as a light microscope aims a beam of light through a specimen. However, instead of lenses made of glass, the transmission electron microscope uses electromagnets as lenses, as do all electron microscopes. The electromagnets bend the electron beam to magnify and focus an image onto a viewing screen or photographic film.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Electron microscopes have truly revolutionized the study of cells and cell organelles. Nonetheless, they have not replaced the light microscope. One problem with electron microscopes is that they cannot be used to study living specimens because the specimen must be held in a vacuum chamber; that is, all the air and liquid must be removed. For a biologist studying a living process, such as the whirling movement of a bacterium, a light microscope equipped with a video camera might be better than either a scanning electron microscope or a transmission electron microscope. Thus, the light microscope remains a useful tool, especially for studying living cells. The size of a cell often determines the type of microscope a biologist uses to study it.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;">  THE RACOON&#39;S SUCCESS                                                                                          </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Raccoons have a vast transcontinental distribution, occurring throughout most of North America and Central America. They are found from southern Canada all the way to Panama, as well as on islands near coastal areas. They occur in each of the 49 states of the continental United States. Although raccoons are native only to the Western Hemisphere, they have been successfully transplanted to other parts of the globe.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Following a decline to a relatively low population level in the 1930s, raccoons began to prosper following their 1943 breeding season. A rapid population surge continued throughout the 1940s, and high numbers have been sustained ever since. By the late 1980s, the number of raccoons in North America was estimated to be at least 15 to 20 times the number that existed during the 1930s. By now, their numbers have undoubtedly grown even more, as they have continued to expand into new habitats where they were once either rare or absent, such as sandy prairies, deserts, coastal marshes, and mountains. Their spread throughout the Rocky Mountain West is indicative  of the  fast pace at which they can exploit  new environments. Despite</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">significant numbers being harvested and having suffered occasional declines, typically because of disease, the raccoon has consistently maintained high population levels.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Several factors explain the raccoon’s dramatic increase in abundance and distribution. First, their success has been partially attributed to the growth of cities, as they often thrive in suburban and even urban settings. Furthermore, they have been deliberately introduced throughout the continent. Within the United States, they are commonly taken from one area to another, both legally and illegally, to restock hunting areas and, presumably, because people simply want them to be part of their local fauna. Their appearance and subsequent flourishing in Utah’s Great Salt Lake valley within the last 40 years appears to be from such an introduction. As an example of the ease with which transplanted individuals can succeed, raccoons from Indiana (midwestern United States) have reportedly been able to flourish on islands off the coast of Alaska.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The raccoon’s expansion in various areas may also be due to the spread of agriculture. Raccoons have been able to exploit crops, especially corn but also cereal grains, which have become dependable food sources for them. The expansion of agriculture, however, does not necessarily lead to rapid increases in their abundance. Farming in Kansas and eastern Colorado (central and western United States) proceeded rapidly in the 1870s and 1880s, but this was about 50 years before raccoons started to spread out from their major habitat, the wooded river bottomlands. They have also expanded into many areas lacking any agriculture other than grazing and into places without forests or permanent streams.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Prior to Europeans settling and farming the Great Plains regionA vast grassland region in North America extending from central Canada south through the west central United States into Texas, raccoons probably were just found along its rivers and streams and in the wooded areas of its southeastern section.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">With the possible exception of the southern part of the province of Manitoba, their absence was notable throughout Canada. They first became more widely distributed in the southern part of Manitoba, and by the 1940s were abundant throughout its southeastern portion. In the 1950s their population swelled in Canada. The control of coyotes in the prairie region in the 1950s may have been a factor in raccoon expansion. If their numbers are sufficient, coyotes might be able to suppress raccoon populations (though little direct evidence supports this notion). By the 1960s the raccoon had become a major predator of the canvasback ducks nesting in southwestern Manitoba.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The extermination of the wolf from most of the contiguous United States may have been a critical factor in the raccoon’s expansion and numerical increase. In the eighteenth century, when the wolf’s range included almost all of North America, raccoons apparently were abundant only in the deciduous forests of the East, Gulf Coast, and Great Lakes regions, though they also extended into the wooded bottomlands of the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Midwest’s major rivers. In such areas, their arboreal habits and the presence of hollow den trees should have offered some protection from wolves and other large predators. Even though raccoons may not have been a significant part of their diet, wolves surely would have tried to prey on those exposed in relatively treeless areas.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> TRANSGENIC PLANTS                                                                                                </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Genes from virtually any organism, from viruses to humans, can now be inserted into plants, creating what are known as transgenic plants. Now used in agriculture, there are approximately 109 million acres of transgenic crops grown worldwide, 68 percent of which are in the United States. The most common transgenic crops are soybeans, corn, cotton, and canola. Most often, these plants either contain a gene making them resistant to the herbicide glyphosate or they contain an insect-resistant gene that produces a protein called Bt toxin.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">On the positive side, proponents of transgenic crops argue that these crops are environmentally friendly because they allow farmers to use fewer and less noxious chemicals for crop production. For example, a 21 percent reduction in the use of insecticide has been reported on Bt cotton (transgenic cotton that produces Bt toxin). In addition, when glyphosate is used to control weeds, other, more persistent herbicides do not need to be applied.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">On the negative side, opponents of transgenic crops suggest that there are many questions that need to be answered before transgenic crops are grown on a large scale. One question deals with the effects that Bt plants have on nontarget organisms such as beneficial insects, worms, and birds that consume the genetically engineered crop. For example, monarch caterpillars feeding on milkweed plants near Bt cornfields will eat some corn pollen that has fallen on the milkweed leaves. Laboratory studies indicate that caterpillars can die from eating Bt pollen. However, field tests indicate that Bt corn is not likely to harm monarchs. Furthermore, the application of pesticides (the alternative to growing Bt plants) has been demonstrated to cause widespread harm to nontarget insects.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Another unanswered question is whether herbicide-resistant genes will move into the populations of weeds. Crop plants are sometimes grown in areas where weedy relatives also live. If the crop plants hybridize and reproduce with weedy relatives, then this herbicide-resistant gene will be perpetuated in the offspring. In this way, the resistant gene can make its way into the weed population. If this happens, a farmer can no longer use glyphosate, for example, to kill those weeds. This scenario is not likely to occur in many instances because there are no weedy relatives growing near the crop plant. However, in some cases, it may become a serious problem. For example, canola readily hybridizes with mustard weed species and could transfer its herbicide-resistant genes to those weeds.</p><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">We know that evolution will occur when transgenic plants are grown on a large scale over a period of time. Of special concern is the development of insect populations resistant to the Bt toxin. This pesticide has been applied to plants for decades without the development of insect-resistant populations. However, transgenic Bt plants express the toxin in all tissues throughout the growing season. Therefore, all insects carrying genes that make them susceptible to the toxin will die. That leaves only the genetically resistant insects alive to perpetuate the population. When these resistant insects mate, they will produce a high proportion of offspring capable of surviving in the presence of the Bt toxin. Farmers are attempting to slow the development of insect resistance in Bt crops by, for example, planting nontransgenic border rows to provide a refuge for susceptible insects. These insects may allow Bt susceptibility to remain in the population.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Perhaps the most serious concern about the transgenic crop plants currently in use is that they encourage farmers to move farther away from sustainable agricultural farming practices, meaning ones that allow natural resources to continually regenerate over the long run. Transgenics, at least superficially, simplify farming by reducing the choices made by the manager. Planting a glyphosate-resistant crop commits a farmer to using that herbicide for the season, probably to the exclusion of all other herbicides and other weed-control practices. Farmers who use Bt transgenics may not feel that they need to follow through with integrated pest-management practices that use beneficial insects and timely applications of pesticides to control insect pests. A more sustainable approach would be to plant nontransgenic corn, monitor the fields throughout the growing season, and then apply a pesticide only if and when needed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">CROP-GROWING SKYSCRAPERS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">11 TEST1</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">By the year 2050, nearly 80% of the Earth&#39;s population will live in urban centres. Applying the most conservative estimates to current demographic trends, the human population will increase by about three billion people by then. An estimated 109 hectares of new land (about 20% larger than Brazil) will be needed to grow enough food to feed them, if traditional farming methods continue as they are practised today. At present, throughout the world, over 80% of the land that is suitable for raising crops is in use. Historically, some 15% of that has been laid waste by poor management practices. What can be done to ensure enough food for the world&#39;s population to live on?</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The concept of indoor farming is not new, since hothouse production of tomatoes and other produce has been in vogue for some time. What is new is the urgent need to scale up this technology to accommodate another three billion people. Many believe an entirely new approach to indoor farming is required, employing cutting-edge technologies. One such proposal is for the &#39;Vertical Farm&#39;. The concept is of multi-storey</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">buildings in which food crops are grown in environmentally controlled conditions. Situated in the heart of urban centres, they would drastically reduce the amount of transportation required to bring food to consumers. Vertical farms would need to be efficient, cheap to construct and safe to operate. If successfully implemented, proponents claim, vertical farms offer the promise of urban renewal, sustainable production of a safe and varied food supply (through year-round production of all crops), and the eventual repair of ecosystems that have been sacrificed for horizontal farming.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">It took humans 10,000 years to learn how to grow most of the crops we now take for granted. Along the way, we despoiled most of the land we worked, often turning verdant, natural ecozones into semi-arid deserts. Within that same time frame, we evolved into an urban species, in which 60% of the human population now lives vertically in cities. This means that, for the majority, we humans have shelter from the elements, yet we subject our food-bearing plants to the rigours of the great outdoors and can do no more than hope for a good weather year. However, more often than not now, due to a rapidly changing climate, that is not what happens. Massive floods, long droughts, hurricanes and severe monsoons take their toll each year, destroying millions of tons of valuable crops.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The supporters of vertical farming claim many potential advantages for the system. For instance, crops would be produced all year round, as they would be kept in artificially controlled, optimum growing conditions. There would be no weather-related crop failures due to droughts, floods or pests. All the food could be grown organically, eliminating the need for herbicides, pesticides and fertilisers. The system would greatly reduce the incidence of many infectious diseases that are acquired at the agricultural interface. Although the system would consume energy, it would return energy to the grid via methane generation from composting non- edible parts of plants. It would also dramatically reduce fossil fuel use, by cutting out the need for tractors, ploughs and shipping.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">A major drawback of vertical farming, however, is that the plants would require artificial light. Without it, those plants nearest the windows would be exposed to more sunlight and grow more quickly, reducing the efficiency of the system. Single- storey greenhouses have the benefit of natural overhead light: even so, many still need artificial lighting. A multi-storey facility with no natural overhead light would require far more. Generating enough light could be prohibitively expensive, unless cheap, renewable energy is available, and this appears to be rather a future aspiration than a likelihood for the near future.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One variation on vertical farming that has been developed is to grow plants in stacked trays that move on rails. Moving the trays allows the plants to get enough sunlight. This system is already in operation, and works well within a single-storey</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">greenhouse with light reaching it from above: it is not certain, however, that it can be made to work without that overhead natural light.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Vertical farming is an attempt to address the undoubted problems that we face in producing enough food for a growing population. At the moment, though, more needs to be done to reduce the detrimental impact it would have on the environment, particularly as regards the use of energy. While it is possible that much of our food will be grown in skyscrapers in future, most experts currently believe it is far more likely that we will simply use the space available on urban rooftops.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> THE FALKIRK WHEEL                                                                                                </span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">A unique engineering achievement</p><p style="padding-top: 1pt;padding-left: 10pt;text-indent: 0pt;line-height: 90%;text-align: justify;">The Falkirk Wheel in Scotland is the world&#39;s first and only rotating boat lift. Opened in 2002, it is central to the ambitious <span class="s6">￡ </span>84.5m Millennium Link project to restore navigability across Scotland by reconnecting the historic waterways of the Forth &amp; Clyde and Union Canals.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The major challenge of the project lay in the fact that the Forth &amp; Clyde Canal is situated 35 metres below the level of the Union Canal. Historically, the two canals had been joined near the town of Falkirk by a sequence of 11 locks - enclosed sections of canal in which the water level could be raised or lowered - that stepped down across a distance of 1.5 km. This had been dismantled in 1933, thereby breaking the link. When the project was launched in 1994, the British Waterways authority were keen to create a dramatic twenty-first- century landmark which would not only be a fitting commemoration of the Millennium, but also a lasting symbol of the economic regeneration of the region.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Numerous ideas were submitted for the project, including concepts ranging from rolling eggs to tilting tanks, from giant see- saws to overhead monorails. The eventual winner was a plan for the huge rotating steel boat lift which was to become The Falkirk Wheel. The unique shape of the structure is claimed to have been inspired by various sources, both manmade and natural, most notably a Celtic double- headed axe, but also the vast turning propeller of a ship, the ribcage of a whale or the spine of a fish.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The various parts of The Falkirk Wheel were all constructed and assembled, like one giant toy building set, at Butterley Engineering&#39;s Steelworks in Derbyshire, some 400 km from Falkirk. A team there carefully assembled the 1,200 tonnes of steel, painstakingly fitting the pieces together to an accuracy of just 10 mm to ensure a perfect final fit. In the summer of 2001, the structure was then dismantled and transported on 35 lorries to Falkirk, before all being bolted back together again on the ground, and finally lifted into position in five large sections by crane. The Wheel would need to withstand immense and constantly changing stresses as it rotated, so to make the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">structure more robust, the steel sections were bolted rather than welded together. Over 45,000 bolt holes were matched with their bolts, and each bolt was hand-tightened.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: left;">The Wheel consists of two sets of opposing axe-shaped arms, attached about 25 metres apart to a fixed central spine. Two diametrically opposed water-filled &#39;gondolas&#39;, each with a capacity of 360,000 litres, are fitted between the ends of the arms. These gondolas always weigh the same, whether or not they are carrying boats. This is because, according to Archimedes&#39; principle of displacement, floating objects displace their own weight in water. So when a boat enters a gondola, the amount of water leaving the gondola weighs exactly the same as the boat. This keeps the Wheel balanced and so, despite its enormous mass, it rotates through 180°in five and a half minutes while using very little power. It takes just 1.5 kilowatt-hours (5.4 M J) of energy to rotate the Wheel</p><ul id="l1"><li><p style="padding-left: 18pt;text-indent: -8pt;text-align: left;">roughly the same as boiling eight small domestic kettles of water.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Boats needing to be lifted up enter the canal basin at the level of the Forth &amp; Clyde Canal and then enter the lower gondola of the Wheel. Two hydraulic steel gates are raised, so as to seal the gondola off from the water in the canal basin. The water between the gates is then pumped out. A hydraulic clamp, which prevents the arms of the Wheel moving while the gondola is docked, is removed, allowing the Wheel to turn. In the central machine room an array of ten hydraulic motors then begins to rotate the central axle. The axle connects to the outer arms of the Wheel, which begin to rotate at a speed of 1/8 of a revolution per minute. As the wheel rotates, the gondolas are kept in the upright position by a simple gearing system. Two eight-metre-wide cogs orbit a fixed inner cog of the same width, connected by two smaller cogs travelling in the opposite direction to the outer cogs - so ensuring that the gondolas always remain level. When the gondola reaches the top, the boat passes straight onto the aqueduct situated 24 metres above the canal basin.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The remaining 11 metres of lift needed to reach the Union Canal is achieved by means of a pair of locks. The Wheel could not be constructed to elevate boats over the full 35-metre difference between the two canals, owing to the presence of the historically important Antonine Wall, which was built by the Romans in the second century AD. Boats travel under this wall via a tunnel, then through the locks, and finally on to the Union Canal.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> REDUCING THE EFFECTS OF CLIMATE CHANGE                                           </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Mark Rowe Reports on the Increasingly Ambitious Geo-Engineering Projects Being Explored By Scientists</p><ol id="l2"><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Such is our dependence on fossil fuels, and such is the volume of carbon dioxide already released into the atmosphere, that many experts agree that significant global warming is now inevitable. They believe that the best we can do is keep it at a reasonable level, and at present the only serious option for doing this is cutting back on our carbon emissions. But while a few countries are making major strides in this regard, the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">majority are having great difficulty even stemming the rate of increase, let alone reversing it. Consequently, an increasing number of scientists are beginning to explore the alternative of geo-engineering - a term which generally refers to the intentional large-scale manipulation of the environment. According to its proponents, geo- engineering is the equivalent of a backup generator: if Plan A - reducing our dependency on fossil fuels - fails, we require a Plan B, employing grand schemes to slow down or reverse the process of global warming.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Geo-engineering has been shown to work, at least on a small localised scale. For decades, May Day parades in Moscow have taken place under clear blue skies, aircraft having deposited dry ice, silver iodide and cement powder to disperse clouds. Many of the schemes now suggested look to do the opposite, and reduce the amount of sunlight reaching the planet. The most eye-catching idea of all is suggested by Professor Roger Angel of the University of Arizona. His scheme would employ up to 16 trillion minute spacecraft, each weighing about one gram, to form a transparent, sunlight-refracting sunshade in an orbit 1.5 million km above the Earth. This could, argues Angel, reduce the amount of light reaching the Earth by two per cent.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The majority of geo-engineering projects so far carried out - which include planting forests in deserts and depositing iron in the ocean to stimulate the growth of algae - have focused on achieving a general cooling of the Earth. But some look specifically at reversing the melting at the poles, particularly the Arctic. The reasoning is that if you replenish the ice sheets and frozen waters of the high latitudes, more light will be reflected back into space, so reducing the warming of the oceans and atmosphere.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The concept of releasing aerosol sprays into the stratosphere above the Arctic has been proposed by several scientists. This would involve using sulphur or hydrogen sulphide aerosols so that sulphur dioxide would form clouds, which would, in turn, lead to a global dimming. The idea is modelled on historic volcanic explosions, such as that of Mount Pinatubo in the Philippines in 1991, which led to a short-term cooling of global temperatures by 0.5℃.Scientists have also scrutinised whether it&#39;s possible to preserve the ice sheets of Greenland with reinforced high-tension cables, preventing icebergs from moving into the sea. Meanwhile in the Russian Arctic, geo-engineering plans include the planting of millions of birch trees. Whereas the region&#39;s native evergreen pines shade the snow and absorb radiation, birches would shed their leaves in winter, thus enabling radiation to be reflected by the snow. Re-routing Russian rivers to increase cold water flow to ice-forming areas could also be used to slow down warming, say some climate scientists.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">But will such schemes ever be implemented? Generally speaking, those who are most cautious about geo-engineering are the scientists involved in the research. Angel says that his plan is &#39;no substitute for developing renewable energy: the only permanent solution&#39;. And Dr Phil Rasch of the US-based Pacific Northwest National Laboratory is</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">equally guarded about the role of geo- engineering: &#39;I think all of us agree that if we were to end geo-engineering on a given day, then the planet would return to its pre- engineered condition very rapidly, and probably within ten to twenty years. That&#39;s certainly something to worry about.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The US National Center for Atmospheric Research has already suggested that the proposal to inject sulphur into the atmosphere might affect rainfall patterns across the tropics and the Southern Ocean. &#39;Geo-engineering plans to inject stratospheric aerosols or to seed clouds would act to cool the planet, and act to increase the extent of sea ice,&#39; says Rasch. &#39;But all the models suggest some impact on the distribution of precipitation.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&#39;A further risk with geo-engineering projects is that you can &quot;overshoot&quot;,&#39; says Dr Dan Lunt, from the University of Bristol&#39;s School of Geophysical Sciences, who has studied the likely impacts of the sunshade and aerosol schemes on the climate. &#39;You may bring global temperatures back to pre-industrial levels, but the risk is that the poles will still be warmer than they should be and the tropics will be cooler than before industrialisation.&#39; To avoid such a scenario, Lunt says Angel&#39;s project would have to operate at half strength; all of which reinforces his view that the best option is to avoid the need for geo-engineering altogether.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The main reason why geo-engineering is supported by many in the scientific community is that most researchers have little faith in the ability of politicians to agree</p></li></ol></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">and then bring in - the necessary carbon cuts. Even leading conservation organisations see the value of investigating the potential of geo-engineering. According to Dr Martin Sommerkorn, climate change advisor for the World Wildlife Fund&#39;s International Arctic Programme, &#39;Human-induced climate change has brought humanity to a position where we shouldn&#39;t exclude thinking thoroughly about this topic and its possibilities.&#39;</p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">RAISING THE MARY ROSE</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">11 TEST2</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">How a Sixteenth-Century Warship Was Recovered From the Seabed</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">On 19 July 1545, English and French fleets were engaged in a sea battle off the coast of southern England in the area of water called the Solent, between Portsmouth and the Isle of Wight. Among the English vessels was a warship by the name of Mary Rose. Built in Portsmouth some 35 years earlier, she had had a long and successful fighting career, and was a favourite of King Henry VIII. Accounts of what happened to the ship vary: while witnesses agree that she was not hit by the French, some maintain that she was outdated, overladen and sailing too low in the water, others that she was mishandled by undisciplined crew. What is undisputed, however, is that the Mary Rose sank into the Solent that day, taking at least 500 men with her. After the battle, attempts were made to recover the ship, but these failed.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">The Mary Rose came to rest on the seabed, lying on her starboard (right) side at an angle of approximately 60 degrees. The hull (the body of the ship) acted as a trap for the sand and mud carried by Solent currents. As a result, the starboard side filled rapidly, leaving the exposed port (left) side to be eroded by marine organisms and mechanical degradation. Because of the way the ship sank, nearly all of the starboard half survived intact. During the seventeenth and eighteenth centuries, the entire site became covered with a layer of hard grey clay, which minimised further erosion.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Then, on 16 June 1836, some fishermen in the Solent found that their equipment was caught on an underwater obstruction, which turned out to be the Mary Rose. Diver John Deane happened to be exploring another sunken ship nearby, and the fishermen approached him, asking him to free their gear. Deane dived down, and found the equipment caught on a timber protruding slightly from the seabed. Exploring further, he uncovered several other timbers and a bronze gun. Deane continued diving on the site intermittently until 1840, recovering several more guns, two bows, various timbers, part of a pump and various other small finds.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The Mary Rose then faded into obscurity for another hundred years. But in 1965, military historian and amateur diver Alexander McKee, in conjunction with the British Sub-Aqua Club, initiated a project called &#39;Solent Ships&#39;. While on paper this was a plan to examine a number of known wrecks in the Solent, what McKee really hoped for was to find the Mary Rose. Ordinary search techniques proved unsatisfactory, so McKee entered into collaboration with Harold E. Edgerton, professor of electrical engineering at the Massachusetts Institute of Technology. In 1967, Edgerton&#39;s side-scan sonar systems revealed a large, unusually shaped object, which McKee believed was the Mary Rose.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Further excavations revealed stray pieces of timber and an iron gun. But the climax to the operation came when, on 5 May 1971, part of the ship&#39;s frame was uncovered. McKee and his team now knew for certain that they had found the wreck, but were as yet unaware that it also housed a treasure trove of beautifully preserved artefacts. Interest in the project grew, and in 1979, The Mary Rose Trust was formed, with Prince Charles as its President and Dr Margaret Rule its Archaeological Director. The decision whether or not to salvage the wreck was not an easy one, although an excavation in 1978 had shown that it might be possible to raise the hull. While the original aim was to raise the hull if at all feasible, the operation was not given the go-ahead until January 1982, when all the necessary information was available.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">An important factor in trying to salvage the Mary Rose was that the remaining hull was an open shell. This led to an important decision being taken: namely to carry out the lifting operation in three very distinct stages. The hull was attached to a lifting frame via a network of bolts and lifting wires. The problem of the hull being sucked back downwards into the mud was overcome by using 12 hydraulic jacks. These raised it a</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">few centimetres over a period of several days, as the lifting frame rose slowly up its four legs. It was only when the hull was hanging freely from the lifting frame, clear of the seabed and the suction effect of the surrounding mud, that the salvage operation progressed to the second stage. In this stage, the lifting frame was fixed to a hook attached to a crane, and the hull was lifted completely clear of the seabed and transferred underwater into the lifting cradle. This required precise positioning to locate the legs into the &#39;stabbing guides&#39; of the lifting cradle. The lifting cradle was designed to fit the hull using archaeological survey drawings, and was fitted with air bags to provide additional cushioning for the hull&#39;s delicate timber framework. The third and final stage was to lift the entire structure into the air, by which time the hull was also supported from below. Finally, on 11 October 1982, millions of people around the world held their breath as the timber skeleton of the Mary Rose was lifted clear of the water, ready to be returned home to Portsmouth.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> WHAT DESTROYED THE CIVILISATION OF EASTER ISLAND?                  </span></p><ol id="l3"><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Easter Island, or Rapu Nui as it is known locally, is home to several hundred ancient human statues - the moai. After this remote Pacific island was settled by the Polynesians, it remained isolated for centuries. All the energy and resources that went into the moai - some of which are ten metres tall and weigh over 7,000 kilos - came from the island itself. Yet when Dutch explorers landed in 1722, they met a Stone Age culture. The moai were carved with stone tools, then transported for many kilometres, without the use of animals or wheels, to massive stone platforms. The identity of the moai builders was in doubt until well into the twentieth century. Thor Heyerdahl, the Norwegian ethnographer and adventurer, thought the statues had been created by pre- Inca peoples from Peru. Bestselling Swiss author Erich von Däniken believed they were built by stranded extraterrestrials. Modern science - linguistic, archaeological and genetic evidence - has definitively proved the moai builders were Polynesians, but not how they moved their creations. Local folklore maintains that the statues walked, while researchers have tended to assume the ancestors dragged the statues somehow, using ropes and logs.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">15</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">When the Europeans arrived, Rapa Nui was grassland, with only a few scrawny trees. In the 1970s and 1980s, though, researchers found pollen preserved in lake sediments, which proved the island had been covered in lush palm forests for thousands of years. Only after the Polynesians arrived did those forests disappear. US scientist Jared Diamond believes that the Rapanui people - descendants of Polynesian settlers - wrecked their own environment. They had unfortunately settled on an extremely fragile island - dry, cool, and too remote to be properly fertilised by windblown volcanic ash. When the islanders cleared the forests for firewood and farming, the forests didn&#39;t grow back. As trees became scarce and they could no longer construct wooden canoes for fishing, they ate birds. Soil erosion decreased their crop yields. Before Europeans arrived, the Rapanui had descended into civil war and cannibalism, he maintains. The</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">collapse of their isolated civilisation, Diamond writes, is a &#39;worst-case scenario for what may lie ahead of us in our own future&#39;.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">16</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The moai, he thinks, accelerated the self-destruction. Diamond interprets them as power displays by rival chieftains who, trapped on a remote little island, lacked other ways of asserting their dominance. They competed by building ever bigger figures. Diamond thinks they laid the moai on wooden sledges, hauled over log rails, but that required both a lot of wood and a lot of people. To feed the people, even more land had to be cleared. When the wood was gone and civil war began, the islanders began toppling the moai. By the nineteenth century none were standing.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">17</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Archaeologists Terry Hunt of the University of Hawaii and Carl Lipo of California State University agree that Easter Island lost its lush forests and that it was an &#39;ecological catastrophe&#39; - but they believe the islanders themselves weren&#39;t to blame. And the moai certainly weren&#39;t. Archaeological excavations indicate that the Rapanui went to heroic efforts to protect the resources of their wind-lashed, infertile fields. They built thousands of circular stone windbreaks and gardened inside them, and used broken volcanic rocks to keep the soil moist. In short, Hunt and Lipo argue, the prehistoric Rapanui were pioneers of sustainable farming.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">18</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Hunt and Lipo contend that moai-building was an activity that helped keep the peace between islanders. They also believe that moving the moai required few people and no wood, because they were walked upright. On that issue, Hunt and Lipo say, archaeological evidence backs up Rapanui folklore. Recent experiments indicate that as few as 18 people could, with three strong ropes and a bit of practice, easily manoeuvre a 1,000 kg moai replica a few hundred metres. The figures&#39; fat bellies tilted them forward, and a D-shaped base allowed handlers to roll and rock them side to side.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">19</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Moreover, Hunt and Lipo are convinced that the settlers were not wholly responsible for the loss of the island&#39;s trees. Archaeological finds of nuts from the extinct Easter Island palm show tiny grooves, made by the teeth of Polynesian rats. The rats arrived along with the settlers, and in just a few years, Hunt and Lipo calculate, they would have overrun the island. They would have prevented the reseeding of the slow- growing palm trees and thereby doomed Rapa Nui&#39;s forest, even without the settlers&#39; campaign of deforestation. No doubt the rats ate birds&#39; eggs too. Hunt and Lipo also see no evidence that Rapanui civilisation collapsed when the palm forest did. They think its population grew rapidly and then remained more or less stable until the arrival of the Europeans, who introduced deadly diseases to which islanders had no immunity. Then</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">in the nineteenth century slave traders decimated the population, which shrivelled to 111 people by 1877.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">20</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Hunt and Lipo&#39;s vision, therefore, is one of an island populated by peaceful and ingenious moai builders and careful stewards of the land, rather than by reckless destroyers ruining their own environment and society. &#39;Rather than a case of abject failure, Rapu Nui is an unlikely story of success&#39;, they claim. Whichever is the case, there are surely some valuable lessons which the world at large can learn from the story of Rapa Nui.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> NEUROAESTHETICS                                                                                                    </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">An emerging discipline called neuroaesthetics is seeking to bring scientific objectivity to the study of art, and has already given us a better understanding of many masterpieces. The blurred imagery of Impressionist paintings seems to stimulate the brain&#39;s amygdala, for instance. Since the amygdala plays a crucial role in our feelings, that finding might explain why many people find these pieces so moving.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Could the same approach also shed light on abstract twentieth-century pieces, from Mondrian&#39;s geometrical blocks of colour, to Pollock&#39;s seemingly haphazard arrangements of splashed paint on canvas? Sceptics believe that people claim to like such works simply because they are famous. We certainly do have an inclination to follow the crowd. When asked to make simple perceptual decisions such as matching a shape to its rotated image, for example, people often choose a definitively wrong answer if they see others doing the same. It is easy to imagine that this mentality would have even more impact on a fuzzy concept like art appreciation, where there is no right or wrong answer.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Angelina Hawley-Dolan, of Boston College, Massachusetts, responded to this debate by asking volunteers to view pairs of paintings - either the creations of famous abstract artists or the doodles of infants, chimps and elephants. They then had to judge which they preferred. A third of the paintings were given no captions, while many were labelled  incorrectly -  volunteers  might  think  they  were viewing  a chimp&#39;s messy brushstrokes when they were actually seeing an acclaimed masterpiece. In each set of trials, volunteers generally preferred the work of renowned artists, even when they believed it was by an animal or a child. It seems that the viewer can sense the artist&#39;s vision in paintings, even if they can&#39;t explain why.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Robert Pepperell, an artist based at Cardiff University, creates ambiguous works that are neither entirely abstract nor clearly representational. In one study, Pepperell and his collaborators asked volunteers to decide how &#39;powerful&#39; they considered an artwork to be, and whether they saw anything familiar in the piece. The longer they took to answer these questions, the more highly they rated the piece under scrutiny, and the greater their</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">neural activity. It would seem that the brain sees these images as puzzles, and the harder it is to decipher the meaning, the more rewarding is the moment of recognition.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">And what about artists such as Mondrian, whose paintings consist exclusively of horizontal and vertical lines encasing blocks of colour? Mondrian&#39;s works are deceptively simple, but eye-tracking studies confirm that they are meticulously composed, and that simply rotating a piece radically changes the way we view it. With the originals, volunteers&#39; eyes tended to stay longer on certain places in the image, but with the altered versions they would flit across a piece more rapidly. As a result, the volunteers considered the altered versions less pleasurable when they later rated the work.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In a similar study, Oshin Vartanian of Toronto University asked volunteers to compare original paintings with ones which he had altered by moving objects around within the frame. He found that almost everyone preferred the original, whether it was a Van Gogh still life or an abstract by Miró. Vartania n also found that changing the composition of the paintings reduced activation in those brain areas linked with meaning and interpretation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In another experiment, Alex Forsythe of the University of Liverpool analysed the visual intricacy of different pieces of art, and her results suggest that many artists use a key level of detail to please the brain. Too little and the work is boring, but too much results in a kind of &#39;perceptual overload&#39;, according to Forsythe. What&#39;s more, appealing pieces both abstract and representational, show signs of &#39;fractals&#39;- repeated motifs recurring in different scales. Fractals are common throughout nature, for example in the shapes of mountain peaks or the branches of trees. It is possible that our visual system, which evolved in the great outdoors, finds it easier to process such patterns.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">It is also intriguing that the brain appears to process movement when we see a handwritten letter, as if we are replaying the writer&#39;s moment of creation. This has led some to wonder whether Pollock&#39;s works feel so dynamic because the brain reconstructs the energetic actions the artist used as he painted. This may be down to our brain&#39;s &#39;mirror neurons&#39;, which are known to mimic others&#39; actions. The hypothesis will need to be thoroughly tested, however. It might even be the case that we could use neuroaesthetic studies to understand the longevity of some pieces of artwork. While the fashions of the time might shape what is currently popular, works that are best adapted to our visual system may be the most likely to linger once the trends of previous generations have been forgotten.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">It&#39;s still early days for the field of neuroaesthetics - and these studies are probably only a taste of what is to come. It would, however, be foolish to reduce art appreciation to a set of scientific laws. We shouldn&#39;t underestimate the importance of the style of a particular artist, their place in history and the artistic environment of their time. Abstract</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">art offers both a challenge and the freedom to play with different interpretations. In some ways, it&#39;s not so different to science, where we are constantly looking for systems and decoding meaning so that we can view and appreciate the world in a new way.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">THE STORY OF SILK</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">11 TEST3</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">The History of the World&#39;s Most Luxurious Fabric, From Ancient China to the Present Day</p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Silk is a fine, smooth material produced from the cocoons - soft protective shells - that are made by mulberry silkworms (insect larvae). Legend has it that it was Lei Tzu, wife  of  the Yellow  Emperor, ruler  of  China in  about  3000  BC,  who  discovered silkworms. One account of the story goes that as she was taking a walk in her husband&#39;s gardens, she discovered that silkworms were responsible for the destruction of several mulberry trees. She collected a number of cocoons and sat down to have a rest. It just so happened that while she was sipping some tea, one of the cocoons that she had collected landed in the hot tea and started to unravel into a fine thread. Lei Tzu found that she could wind this thread around her fingers. Subsequently, she persuaded her husband to allow her to rear silkworms on a grove of mulberry trees. She also devised a special reel to draw the fibres from the cocoon into a single thread so that they would be strong enough to be woven into fabric. While it is unknown just how much of this is true, it is certainly known that silk cultivation has existed in China for several millennia.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Originally, silkworm farming was solely restricted to women, and it was they who were responsible for the growing, harvesting and weaving. Silk quickly grew into a symbol of status, and originally, only royalty were entitled to have clothes made of silk. The rules were gradually relaxed over the years until finally during the Qing Dynasty (1644-1911 AD), even peasants, the lowest caste, were also entitled to wear silk. Sometime during the Han Dynasty (206 BC-220 AD), silk was so prized that it was also used as a unit of currency. Government officials were paid their salary in silk, and farmers paid their taxes in grain and silk. Silk was also used as diplomatic gifts by the emperor. Fishing lines, bowstrings, musical instruments and paper were all made using silk. The earliest indication of silk paper being used was discovered in the tomb of a noble who is estimated to have died around 168 AD.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Demand for this exotic fabric eventually created the lucrative trade route now known as the Silk Road, taking silk westward and bringing gold, silver and wool to the East. It was named the Silk Road after its most precious commodity, which was considered to be worth more than gold. The Silk Road stretched over 6,000 kilometres from Eastern China to the Mediterranean Sea, following the Great Wall of China, climbing the Pamir mountain range, crossing modern-day Afghanistan and going on to the Middle East, with a major trading market in Damascus. From there, the merchandise was shipped</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">across the Mediterranean Sea. Few merchants travelled the entire route; goods were handled mostly by a series of middlemen.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">With the mulberry silkworm being native to China, the country was the world&#39;s sole producer of silk for many hundreds of years. The secret of silk-making eventually reached the rest of the world via the Byzantine Empire, which ruled over the Mediterranean region of southern Europe, North Africa and the Middle East during the period 330-1453 AD. According to another legend, monks working for the Byzantine emperor Justinian smuggled silkworm eggs to Constantinople (Istanbul in modern-day Turkey) in 550 AD, concealed inside hollow bamboo walking canes. The Byzantines were as secretive as the Chinese, however, and for many centuries the weaving and trading of silk fabric was a strict imperial monopoly. Then in the seventh century, the Arabs conquered Persia, capturing their magnificent silks in the process. Silk production thus spread through Africa, Sicily and Spain as the Arabs swept through these lands. Andalusia in southern Spain was Europe&#39;s main silk- producing centre in the tenth century. By the thirteenth century, however, Italy had become Europe&#39;s leader in silk production and export. Venetian merchants traded extensively in silk and encouraged silk growers to settle in Italy. Even now, silk processed in the province of Como in northern Italy enjoys an esteemed reputation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The nineteenth century and industrialisation saw the downfall of the European silk industry. Cheaper Japanese silk, trade in which was greatly facilitated by the opening of the Suez Canal, was one of the many factors driving the trend. Then in the twentieth century, new manmade fibres, such as nylon, started to be used in what had traditionally been silk products, such as stockings and parachutes. The two world wars, which interrupted the supply of raw material from Japan, also stifled the European silk industry. After the Second World War, Japan&#39;s silk production was restored, with improved production and quality of raw silk. Japan was to remain the world&#39;s biggest producer of raw silk, and practically the only major exporter of raw silk, until the 1970s. However, in more recent decades, China has gradually recaptured its position as the world&#39;s biggest producer and exporter of raw silk and silk yarn. Today, around 125,000 metric tons of silk are produced in the world, and almost two thirds of that production takes place in China.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> GREAT MIGRATIONS                                                                                                  </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Animal migration, however it is defined, is far more than just the movement of animals. It can loosely be described as travel that takes place at regular intervals - often in an annual cycle - that may involve many members of a species, and is rewarded only after a long journey. It suggests inherited instinct. The biologist Hugh Dingle has identified five characteristics that apply, in varying degrees and combinations, to all migrations. They are prolonged movements that carry animals outside familiar habitats; they tend to be linear, not zigzaggy; they involve special behaviours concerning preparation (such as overfeeding) and arrival; they demand special allocations of energy. And one more:</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">migrating animals maintain an intense attentiveness to the greater mission, which keeps them undistracted by temptations and undeterred by challenges that would turn other animals aside.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">An arctic tern, on its 20,000 km flight from the extreme south of South America to the Arctic circle, will take no notice of a nice smelly herring offered from a bird- watcher&#39;s boat along the way. While local gulls will dive voraciously for such handouts, the tern flies on. Why? The arctic tern resists distraction because it is driven at that moment by an instinctive sense of something we humans find admirable: larger purpose. In other words, it is determined to reach its destination. The bird senses that it can eat, rest and mate later. Right now it is totally focused on the journey; its undivided intent is arrival. Reaching some gravelly coastline in the Arctic, upon which other arctic terns have converged, will serve its larger purpose as shaped by evolution: finding a place, a time, and a set of circumstances in which it can successfully hatch and rear offspring.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">But migration is a complex issue, and biologists define it differently, depending in part on what sorts of animals they study. Joel Berger, of the University of Montana, who works on the American pronghorn and other large terrestrial mammals, prefers what he calls a simple, practical definition suited to his beasts: &#39;movements from a seasonal home area away to another home area and back again&#39;. Generally the reason for such seasonal back-and-forth movement is to seek resources that aren&#39;t available within a single area year-round.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">But daily vertical movements by zooplankton in the ocean - upward by night to seek food, downward by day to escape predators - can also be considered migration. So can the movement of aphids when, having depleted the young leaves on one food plant, their offspring then fly onward to a different host plant, with no one aphid ever returning to where it started.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Dingle is an evolutionary biologist who studies insects. His definition is more intricate than Berger&#39;s, citing those five features that distinguish migration from other forms of movement. They allow for the fact that, for example, aphids will become sensitive to blue light (from the sky) when it&#39;s time for takeoff on their big journey, and sensitive to yellow light (reflected from tender young leaves) when it&#39;s appropriate to land. Birds will fatten themselves with heavy feeding in advance of a long migrational flight. The value of his definition, Dingle argues, is that it focuses attention on what the phenomenon of wildebeest migration shares with the phenomenon of the aphids, and therefore helps guide researchers towards understanding how evolution has produced them all.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Human behaviour, however, is having a detrimental impact on animal migration. The pronghorn, which resembles an antelope, though they are unrelated, is the fastest land mammal of the New World. One population, which spends the summer in the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">mountainous Grand Teton National Park of the western USA, follows a narrow route from its summer range in the mountains, across a river, and down onto the plains. Here they wait out the frozen months, feeding mainly on sagebrush blown clear of snow. These pronghorn are notable for the invariance of their migration route and the severity of its constriction at three bottlenecks. If they can&#39;t pass through each of the three during their spring migration, they can&#39;t reach their bounty of summer grazing; if they can&#39;t pass through again in autumn, escaping south onto those windblown plains, they are likely to die trying to overwinter in the deep snow. Pronghorn, dependent on distance vision and speed to keep safe from predators, traverse high, open shoulders of land, where they can see and run. At one of the bottlenecks, forested hills rise to form a V, leaving a corridor of open ground only about 150 metres wide, filled with private homes. Increasing development is leading toward a crisis for the pronghorn, threatening to choke off their passageway.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Conservation scientists, along with some biologists and land managers within the USA&#39;s National Park Service and other agencies, are now working to preserve migrational behaviours, not just species and habitats. A National Forest has recognised the path of the pronghorn, much of which passes across its land, as a protected migration corridor. But neither the Forest Service nor the Park Service can control what happens on private land at a bottleneck. And with certain other migrating species, the challenge is complicated further - by vastly greater distances traversed, more jurisdictions, more borders, more dangers along the way. We will require wisdom and resoluteness to ensure that migrating species can continue their journeying a while longer.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="662" height="51" alt="image" src="66篇/Image_001.png"/></span></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">PREFACE TO &#39;HOW THE OTHER HALF THINKS: ADVENTURES IN MATHEMATICAL REASONING&#39;</p><ol id="l4"><li><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Occasionally, in some difficult musical compositions, there are beautiful, but easy parts - parts so simple a beginner could play them. So it is with mathematics as well. There are some discoveries in advanced mathematics that do not depend on specialized knowledge, not even on algebra, geometry, or trigonometry. Instead they may involve, at most, a little arithmetic, such as &#39;the sum of two odd numbers is even&#39;, and common sense. Each of the eight chapters in this book illustrates this phenomenon. Anyone can understand every step in the reasoning.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The thinking in each chapter uses at most only elementary arithmetic, and sometimes not even that. Thus all readers will have the chance to participate in a mathematical experience, to appreciate the beauty of mathematics, and to become familiar with its logical, yet intuitive, style of thinking.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">One of my purposes in writing this book is to give readers who haven&#39;t had the opportunity to see and enjoy real mathematics the chance to appreciate the mathematical way of thinking. I want to reveal not only some of the fascinating discoveries, but, more importantly, the reasoning behind them.</p><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">In that respect, this book differs from most books on mathematics written for the general public. Some present the lives of colorful mathematicians. Others describe important applications of mathematics. Yet others go into mathematical procedures, but assume that the reader is adept in using algebra.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">I hope this book will help bridge that notorious gap that separates the two cultures: the humanities and the sciences, or should I say the right brain (intuitive) and the left brain (analytical, numerical). As the chapters will illustrate, mathematics is not restricted to the analytical and numerical; intuition plays a significant role. The alleged gap can be narrowed or completely overcome by anyone, in part because each of us is far from using the full capacity of either side of the brain. To illustrate our human potential, I cite a structural engineer who is an artist, an electrical engineer who is an opera singer, an opera singer who published mathematical research, and a mathematician who publishes short stories.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Other scientists have written books to explain their fields to non-scientists, but have necessarily had to omit the mathematics, although it provides the foundation of their theories. The reader must remain a tantalized spectator rather than an involved participant, since the appropriate language for describing the details in much of science is mathematics, whether the subject is expanding universe, subatomic particles, or chromosomes. Though the broad outline of a scientific theory can be sketched intuitively, when a part of the physical universe is finally understood, its description often looks like a page in a mathematics text.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Still, the non-mathematical reader can go far in understanding mathematical reasoning. This book presents the details that illustrate the mathematical style of thinking, which involves sustained, step-by-step analysis, experiments, and insights. You will turn these pages much more slowly than when reading a novel or a newspaper. It may help to have a pencil and paper ready to check claims and carry out experiments.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">As I wrote, I kept in mind two types of readers: those who enjoyed mathematics until they were turned off by an unpleasant episode, usually around fifth grade, and mathematics aficionados, who will find much that is new throughout the book.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">This book also serves readers who simply want to sharpen their analytical skills. Many careers, such as law and medicine, require extended, precise analysis. Each chapter offers  practice in  following a sustained  and  closely  argued  line of thought. That mathematics can develop this skill is shown by these two testimonials.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">A physician wrote, &#39;The discipline of analytical thought processes [in mathematics] prepared me extremely well for medical school. In medicine one is faced with a problem</p></li></ol><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">which must be thoroughly analyzed before a solution can be found. The process is similar to doing mathematics.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">A lawyer made the same point, &#39;Although I had no background in law - not even one political science course - I did well at one of the best law schools. I attribute much of my success there to having learned, through the study of mathematics, and, in particular, theorems, how to analyze complicated principles. Lawyers who have studied mathematics can master the legal principles in a way that most others cannot.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">I hope you will share my delight in watching as simple, even naïve, questions le ad to remarkable solutions and purely theoretical discoveries find unanticipated applications.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">RESEARCH USING TWINS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">11 TEST4</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">To biomedical researchers all over the world, twins offer a precious opportunity to untangle the influence of genes and the environment - of nature and nurture. Because identical twins come from a single fertilized egg that splits into two, they share virtually the same genetic code. Any differences between them - one twin having younger looking skin, for example - must be due to environmental factors such as less time spent in the sun.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Alternatively, by comparing the experiences of identical twins with those of fraternal twins, who come from separate eggs and share on average half their DNA, researchers can quantify the extent to which our genes affect our lives. If identical twins are more similar to each other with respect to an ailment than fraternal twins are, then vulnerability to the disease must be rooted at least in part in heredity.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">These two lines of research - studying the differences between identical twins to pinpoint the influence of environment, and comparing identical twins with fraternal ones to measure the role of inheritance - have been crucial to understanding the interplay of nature and nurture in determining our personalities, behavior, and vulnerability to disease. The idea of using twins to measure the influence of heredity dates back to 1875, when the English scientist Francis Galton first suggested the approach (and coined the phrase &#39;nature and nurture&#39;). But twin studies took a surprising twist in the 1980s, with the arrival of studies into identical twins who had been separated at birth and reunited as adults. Over two decades 137 sets of twins eventually visited Thomas Bouchard&#39;s lab in what became known as the Minnesota Study of Twins Reared Apart. Numerous tests were carried out on the twins, and they were each asked more than 15,000 questions.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Bouchard and his colleagues used this mountain of data to identify how far twins were affected by their genetic makeup. The key to their approach was a statistical</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">concept called heritability. In broad terms, the heritability of a trait measures the extent to which differences among members of a population can be explained by differences in their genetics. And wherever Bouchard and other scientists looked, it seemed, they found the invisible hand of genetic influence helping to shape our lives.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: left;">Lately, however, twin studies have helped lead scientists to a radical new conclusion: that nature and nurture are not the only elemental forces at work. According to a recent field called epigenetics, there is a third factor also in play, one that in some cases serves as a bridge between the environment and our genes, and in others operates on its own to shape who we are.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Epigenetic processes are chemical reactions tied to neither nature nor nurture but representing what researchers have called a &#39;third component&#39;. These reactions influence how our genetic code is expressed: how each gene is strengthened or weakened, even turned on or off, to build our bones, brains and all the other parts of our bodies.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">If you think of our DNA as an immense piano keyboard and our genes as the keys - each key symbolizing a segment of DNA responsible for a particular note, or trait, and all the keys combining to make us who we are - then epigenetic processes determine when and how each key can be struck, changing the tune being played.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One way the study of epigenetics is revolutionizing our understanding of biology is by revealing a mechanism by which the environment directly impacts on genes. Studies of animals, for example, have shown that when a rat experiences stress during pregnancy, it can cause epigenetic changes in a fetus that lead to behavioral problems as the rodent grows up. Other epigenetic processes appear to occur randomly, while others are normal, such as those that guide embryonic cells as they become heart, brain, or liver cells, for example.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Geneticist Danielle Reed has worked with many twins over the years and thought deeply about what twin studies have taught us. &#39;It&#39;s very clear when you look at twins that much of what they share is hardwired,&#39; she says. &#39;Many things about them are absolutely the same and unalterable. But it&#39;s also clear, when you get to know them, that other things about them are different. Epigenetics is the origin of a lot of those differences, in my view.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Reed credits Thomas Bouchard&#39;s work for today&#39;s surge in twin studies. &#39;He was the trailblazer,&#39; she says. &#39;We forget that 50 years ago things like heart disease were thought to be caused entirely by lifestyle. Schizophrenia was thought to be due to poor mothering. Twin studies have allowed us to be more reflective about what people are actually born with and what&#39;s caused by experience.&#39;</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Having said that, Reed adds, the latest work in epigenetics promises to take our understanding even further. &#39;What I like to say is that nature writes some things in pencil and some things in pen,&#39; she says. &#39;Things written in pen you can&#39;t change. That&#39;s DNA. But things written in pencil you can. That&#39;s epigenetics. Now that we&#39;re actually able to look at the DNA and see where the pencil writings are, it&#39;s sort of a whole new world.&#39;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> AN INTRODUCTION TO FILM SOUND                                                                  </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Though we might think of film as an essentially visual experience, we really cannot afford to underestimate the importance of film sound. A meaningful sound track is often as complicated as the image on the screen, and is ultimately just as much the responsibility of the director. The entire sound track consists of three essential ingredients: the human voice, sound effects and music. These three tracks must be mixed and balanced so as to produce the necessary emphases which in turn create desired effects. Topics which essentially refer to the three previously mentioned tracks are discussed below. They include dialogue, synchronous and asynchronous sound effects, and music.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Let us start with dialogue. As is the case with stage drama, dialogue serves to tell the story and expresses feelings and motivations of characters as well. Often with film characterization the audience perceives little or no difference between the character and the actor. Thus, for example, the actor Humphrey Bogart is the character Sam Spade; film personality and life personality seem to merge. Perhaps this is because the very texture of a performer&#39;s voice supplies an element of character.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">When voice textures fit the performer&#39;s physiognomy and gestures, a whole and very realistic persona emerges. The viewer sees not an actor working at his craft, but another human being struggling with life. It is interesting to note that how dialogue is used and the very amount of dialogue used varies widely among films. For example, in the highly successful science-fiction film 2001, little dialogue was evident, and most of it was banal and of little intrinsic interest. In this way the film-maker was able to portray what Thomas Sobochack and Vivian Sobochack call, in An Introduction to Film, the &#39;inadequacy of human responses when compared with the magnificent technology created by man and the visual beauties of the universe&#39;.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The comedy Bringing Up Baby, on the other hand, presents practically non-stop dialogue delivered at breakneck speed. This use of dialogue underscores not only the dizzy quality of the character played by Katherine Hepburn, but also the absurdity of the film itself and thus its humor. The audience is bounced from gag to gag and conversation to conversation; there is no time for audience reflection. The audience is caught up in a whirlwind of activity in simply managing to follow the plot. This film presents pure escapism - largely due to its frenetic dialogue.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Synchronous sound effects are those sounds which are synchronized or matched with what is viewed. For example, if the film portrays a character playing the piano, the sounds of the piano are projected. Synchronous sounds contribute to the realism of film and also help to create a particular atmosphere. For example, the &quot;click&#39; of a door being opened may simply serve to convince the audience that the image portrayed is real, and the audience may only subconsciously note the expected sound. However, if the &#39;click&#39; of an opening door is part of an ominous action such as a burglary, the sound mixer may call attention to the &#39;click&#39; with an increase in volume; this helps to engage the audience in a moment of suspense.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Asynchronous sound effects, on the other hand, are not matched with a visible source of the sound on screen. Such sounds are included so as to provide an appropriate emotional nuance, and they may also add to the realism of the film. For example, a film- maker might opt to include the background sound of an ambulance&#39;s siren while the foreground sound and image portrays an arguing couple. The asynchronous ambulance siren underscores the psychic injury incurred in the argument; at the same time the noise of the siren adds to the realism of the film by acknowledging the film&#39;s city setting.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">We are probably all familiar with background music in films, which has become so ubiquitous as to be noticeable in its absence. We are aware that it is used to add emotion and rhythm. Usually not meant to be noticeable, it often provides a tone or an emotional attitude toward the story and/or the characters depicted. In addition, background music often foreshadows a change in mood. For example, dissonant music may be used in film to indicate an approaching (but not yet visible) menace or disaster.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Background music may aid viewer understanding by linking scenes. For example, a particular musical theme associated with an individual character or situation may be repeated at various points in a film in order to remind the audience of salient motifs or ideas.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Film sound comprises conventions and innovations. We have come to expect an acceleration of music during car chases and creaky doors in horror films. Yet, it is important to note as well that sound is often brilliantly conceived. The effects of sound are often largely subtle and often are noted by only our subconscious minds. We need to foster an awareness of film sound as well as film space so as to truly appreciate an art form that sprang to life during the twentieth century - the modern film.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 10pt;text-indent: -4pt;line-height: 118%;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> &#39;THIS MARVELLOUS INVENTION&#39;</span><span class="p"> 27</span></p><ol id="l5"><li><p style="padding-left: 52pt;text-indent: -42pt;line-height: 13pt;text-align: justify;">Of all mankind&#39;s manifold creations, language must take pride of place. Other</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">inventions - the wheel, agriculture, sliced bread - may have transformed our material existence, but the advent of language is what made us human. Compared to language, all other inventions pale in significance, since everything we have ever achieved</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">depends on language and originates from it. Without language, we could never have embarked on our ascent to unparalleled power over all other animals, and even over nature itself.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">28</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">But language is foremost not just because it came first. In its own right it is a tool of extraordinary sophistication, yet based on an idea of ingenious simplicity: &#39;this marvellous invention of composing out of twenty-five or thirty sounds that infinite variety of expressions which, whilst having in themselves no likeness to what is in our mind, allow us to disclose to others its whole secret, and to make known to those who cannot penetrate it all that we imagine, and all the various stirrings of our soul&#39;. This was how, in 1660, the renowned French grammarians of the Port-Royal abbey near Versailles distilled the essence of language, and no one since has celebrated more eloquently the magnitude of its achievement. Even so, there is just one flaw in all these hymns of praise, for the homage to language&#39;s unique accomplishment conceals a simple yet critical incongruity. Language is mankind&#39;s greatest invention - except, of course, that it was never invented. This apparent paradox is at the core of our fascination with language, and it holds many of its secrets.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">29</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Language often seems so skillfully drafted that one can hardly imagine it as anything other than the perfected handiwork of a master craftsman. How else could this instrument make so much out of barely three dozen measly morsels of sound? In themselves, these configurations of mouth -p,fb,v,t,d,k,g,sh,a,e and so on - amount to nothing more than a few haphazard spits and splutters, random noises with no meaning, no ability to express, no power to explain. But run them through the cogs and wheels of the language machine, let it arrange them in some very special orders, and there is nothing that these meaningless streams of air cannot do: from sighing the interminable boredom of existence to unravelling the fundamental order of the universe.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">30</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The most extraordinary thing about language, however, is that one doesn&#39;t have to be a genius to set its wheels in motion. The language machine allows just about everybody - from pre-modern foragers in the subtropical savannah, to post-modern philosophers in the suburban sprawl - to tie these meaningless sounds together into an infinite variety of subtle senses, and all apparently without the slightest exertion. Yet it is precisely this deceptive ease which makes language a victim of its own success, since in everyday life its triumphs are usually taken for granted. The wheels of language run so smoothly that one rarely bothers to stop and think about all the resourcefulness and expertise that must have gone into making it tick. Language conceals art.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">31</p></li><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Often, it is only the estrangement of foreign tongues, with their many exotic and outlandish features, that brings home the wonder of language&#39;s design. One of the showiest stunts that some languages can pull off is an ability to build up words of breath- breaking length, and thus express in one word what English takes a whole sentence to say. The Turkish word şehirliliştiremediklerimizdensiniz, to take one example, means nothing less than &#39;you are one of those whom we can&#39;t turn into a town-dweller&#39;. (In case you were wondering, this monstrosity really is one word, not merely many different words squashed together - most of its components cannot even stand up on their own.)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">32</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">And if that sounds like some one-off freak, then consider Sumerian, the language spoken on the banks of the Euphrates some 5,000 years ago by the people who invented writing and thus enabled the documentation of history. A Sumerian word like munintuma&#39;a (&#39;when he had made it suitable for her&#39;) might seem rather trim compared to the Turkish colossus above. What is so impressive about it, however, is not its lengthiness but rather the reverse - the thrifty compactness of its construction. The word is made up of different slots, each corresponding to a particular portion of meaning. This sleek design allows single sounds to convey useful information, and in fact even the absence of a sound has been enlisted to express something specific. If you were to ask which bit in the Sumerian word corresponds to the pronoun &#39;it&#39; in the English translation &#39;when he had made it suitable for her&#39;, then the answer would have to be nothing. Mind you, a very particular kind of nothing: the nothing that stands in the empty slot in the middle. The technology is so fine-tuned then that even a non-sound, when carefully placed in a particular position, has been invested with a specific function. Who could possibly have come up with such a nifty contraption?</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">CORK</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">12 TEST5</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Cork - the thick bark of the cork oak tree (Quercus suber) - is a remarkable material. It is tough, elastic, buoyant, and fire-resistant, and suitable for a wide range of purposes. It has also been used for millennia: the ancient Egyptians sealed their sarcophagi (stone coffins) with cork, while the ancient Greeks and Romans used it for anything from beehives to sandals.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">And the cork oak itself is an extraordinary tree. Its bark grows up to 20cm in thickness, insulating the tree like a coat wrapped around the trunk and branches and keeping the inside at a constant 20°C all year round. Developed most probably as a defence against forest fires, the bark of the cork oak has a particular cellular structure - with about 40 million cells per cubic centimetre - that technology has never succeeded in replicating. The cells are filled with air, which is why cork is so buoyant. It also has an elasticity that means you can squash it and watch it spring back to its original size and shape when you release the pressure.</p><p style="padding-top: 7pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">Cork oaks grow in a number of Mediterranean countries, including Portugal, Spain, Italy, Greece and Morocco. They flourish in warm, sunny climates where there is a minimum of 400 millimetres of rain per year, and not more than 800 millimetres. Like grape vines, the trees thrive in poor soil, putting down deep roots in search of moisture and nutrients.Southern Portugal’s Alentejo region meets all of these requirements, which explains why, by the early 20th century, this region had become the world’s largest producer of cork, and why today it accounts for roughly half of all cork production around the world.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Most cork forests are family-owned. Many of these family businesses, and indeed many of the trees themselves, are around 200 years old. Cork production is, above all, an exercise in patience. From the planting of a cork sapling to the first harvest takes 25 years, and a gap of approximately a decade must separate harvests from an individual tree. And for top-quality cork, it’s necessary to wait a further 15 or 20 years. You even have to wait for the right kind of summer’s day to harvest cork. If the bark is stripped on a day when it’s too cold - or when the air is damp - the tree will be damaged.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Cork harvesting is a very specialised profession. No mechanical means of stripping cork bark has been invented, so the job is done by teams of highly skilled workers. First, they make vertical cuts down the bark using small sharp axes, then lever it away in pieces as large as they can manage. The most skilful cork-strippers prise away a semi- circular husk that runs the length of the trunk from just above ground level to the first branches. It is then dried on the ground for about four months, before being taken to factories, where it is boiled to kill any insects that might remain in the cork. Over 60% of cork then goes on to be made into traditional bottle stoppers, with most of the remainder being used in the construction trade. Corkboard and cork tiles are ideal for thermal and acoustic insulation, while granules of cork are used in the manufacture of concrete.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Recent years have seen the end of the virtual monopoly of cork as the material for bottle stoppers, due to concerns about the effect it may have on the contents of the bottle. This is caused by a chemical compound called 2,4,6-trichloroanisole (TCA), which forms through the interaction of plant phenols, chlorine and mould. The tiniest concentrations - as little as three or four parts to a trillion - can spoil the taste of the product contained in the bottle. The result has been a gradual yet steady move first towards plastic stoppers and, more recently, to aluminium screw caps. These substitutes are cheaper to manufacture and, in the case of screw caps, more convenient for the user.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The classic cork stopper does have several advantages, however. Firstly, its traditional image is more in keeping with that of the type of high quality goods with which it has long been associated. Secondly - and very importantly - cork is a sustainable product that can be recycled without difficulty. Moreover, cork forests are a resource</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">which support local biodiversity, and prevent desertification in the regions where they are planted. So, given the current concerns about environmental issues, the future of this ancient material once again looks promising.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> COLLECTING AS A HOBBY                                                                                      </span></p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Collecting must be one of the most varied of human activities, and it&#39;s one that many of us psychologists find fascinating. Many forms of collecting have been dignified with a technical name: an archtophilist collects teddy bears, a philatelist collects postage stamps, and a deltiologist collects postcards. Amassing hundreds or even thousands of postcards, chocolate wrappers or whatever, takes time, energy and money that could surely be put to much more productive use. And yet there are millions of collectors around the world. Why do they do it?</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">There are the people who collect because they want to make money - this could be called an instrumental reason for collecting; that is, collecting as a means to an end. They&#39;ll look for, say, antiques that they can buy cheaply and expect to be able to sell at a profit. But there may well be a psychological element, too - buying cheap and selling dear can give the collector a sense of triumph. And as selling online is so easy, more and more people are joining in.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Many collectors collect to develop their social life, attending meetings of a group of collectors and exchanging information on items. This is a variant on joining a bridge club or a gym, and similarly brings them into contact with like-minded people.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Another motive for collecting is the desire to find something special, or a particular example of the collected item, such as a rare early recording by a particular singer. Some may spend their whole lives in a hunt for this. Psychologically, this can give a purpose to a life that otherwise feels aimless. There is a danger, though, that if the individual is ever lucky enough to find what they&#39;re looking for, rather than celebrating their success, they may feel empty, now that the goal that drove them on has gone.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">If you think about collecting postage stamps, another potential reason for it - or, perhaps, a result of collecting - is its educational value. Stamp collecting opens a window to other countries, and to the plants, animals, or famous people shown on their stamps. Similarly, in the 19th century, many collectors amassed fossils, animals and plants from around the globe, and their collections provided a vast amount of information about the natural world. Without those collections, our understanding would be greatly inferior to what it is.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In the past - and nowadays, too, though to a lesser extent - a popular form of collecting, particularly among boys and men, was trainspotting. This might involve trying to see every locomotive of a particular type, using published data that identifies each one, and ticking off each engine as it is seen. Trainspotters exchange information,</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">these days often by mobile phone, so they can work out where to go to, to see a particular engine. As a by•product, many practitioners  of the hobby become very knowledgeable about railway operations, or the technical specifications of different engine types.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Similarly, people who collect dolls may go beyond simply enlarging their collection, and develop an interest in the way that dolls are made, or the materials that are used. These have changed over the centuries from the wood that was standard in 16th century Europe, through the wax and porcelain of later centuries, to the plastics of today&#39;s dolls. Or collectors might be inspired to study how dolls reflect notions of what children like, or ought to like.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Not all collectors are interested in learning from their hobby, though, so what we might call a psychological reason for collecting is the need for a sense of control, perhaps as a way of dealing with insecurity. Stamp collectors, for instance, arrange their stamps in albums, usually very neatly, organising their collection according to certain commonplace principles - perhaps by country in alphabetical order, or grouping stamps by what they depict - people, birds, maps, and so on.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One reason, conscious or not, for what someone chooses to collect is to show the collector&#39;s individualism. Someone who decides to collect something as unexpected as dog collars, for instance, may be conveying their belief that they must be interesting themselves. And believe it or not, there is at least one dog collar museum in existence, and it grew out of a personal collection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Of course, all hobbies give pleasure, but the common factor in collecting is usually passion: pleasure is putting it far too mildly. More than most other hobbies, collecting can be totally engrossing, and can give a strong sense of personal fulfilment. To non- collectors it may appear an eccentric, if harmless, way of spending time, but potentially, collecting has a lot going for it.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> WHAT’S THE PURPOSE OF GAINING KNOWLEDGE?                                     </span></p><ol id="l6"><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">‘I would found an institution where any person can find instruction in any subject.’ That was the founder’s motto for Cornell University, and it seems an apt characterization of the different university, also in the USA, where I currently teach philosophy. A student can prepare for a career in resort management, engineering, interior design, accounting, music, law enforcement, you name it. But what would the founders of these two institutions have thought of a course called &#39;Arson for Profit’? I kid you not: we have it on the books. Any undergraduates who have met the academic requirements can sign up for the course in our program in &#39;fire science&#39;.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">28</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">Naturally, the course is intended for prospective arson investigators, who can learn all the tricks of the trade for detecting whether a fire was deliberately set,</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">discovering who did it, and establishing a chain of evidence for effective prosecution in a court of law. But wouldn’t this also be the perfect course for prospective arsonists to sign up for? My point is not to criticize academic programs in fire science: they are highly welcome as part of the increasing professionalization of this and many other occupations. However, it’s not unknown for a firefighter to torch a building. This example suggests how dishonest and illegal behavior, with the help of higher education, can creep into every aspect of public and business life.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">29</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">I realized this anew when I was invited to speak before a class in marketing, which is another of our degree programs. The regular instructor is a colleague who appreciates the kind of ethical perspective I can bring as a philosopher. There are endless ways I could have approached this assignment, but I took my cue from the title of the course: ‘Principles of Marketing’. It made me think to ask the students, ‘Is marketing principled?’ After all, a subject matter can have principles in the sense of being codified, having rules, as with football or chess, without being principled in the sense of being ethical. Many of the students immediately assumed that the answer to my question about marketing principles was obvious: no. Just look at the ways in which everything under the sun has been marketed; obviously it need not be done in a principled (=ethical) fashion.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">30</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Is that obvious? I made the suggestion, which may sound downright crazy in light of the evidence, that perhaps marketing is by definition principled. My inspiration for this judgement is the philosopher Immanuel Kant, who argued that any body of knowledge consists of an end (or purpose) and a means.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">31</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Let us apply both the terms ‘means’ and ‘end’ to marketing. The students have signed up for a course in order to learn how to market effectively. But to what end? There seem to be two main attitudes toward that question. One is that the answer is obvious: the purpose of marketing is to sell things and to make money. The other attitude is that the purpose of marketing is irrelevant: each person comes to the program and course with his or her own plans, and these need not even concern the acquisition of marketing expertise as such. My proposal, which I believe would also be Kant’s, is that neither of these attitudes captures the significance of the end to the means for marketing. A field of knowledge or a professional endeavor is defined by both the means and the end; hence both deserve scrutiny. Students need to study both how to achieve X, and also what X is.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">32</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">It is at this point that ‘Arson for Profit’ becomes supremely relevant. That course is presumably all about means: how to detect and prosecute criminal activity. It is</p></li></ol><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">therefore assumed that the end is good in an ethical sense. When I ask fire science students to articulate the end, or purpose, of their field, they eventually generalize to something like, ‘The safety and welfare of society,’ which seems right. As we have seen, someone could use the very same knowledge of means to achieve a much less noble end, such as personal profit via destructive, dangerous, reckless activity. But we would not call that firefighting. We have a separate word for it: arson. Similarly, if you employed the ‘principles of marketing’ in an unprincipled way, you would not be doing marketing. We have another term for it: fraud. Kant gives the example of a doctor and a poisoner, who use the identical knowledge to achieve their divergent ends. We would say that one is practicing medicine, the other, murder.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">THE RISKS AGRICULTURE FACES IN DEVELOPING COUNTRIES</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">12 TEST6</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">Synthesis of an online debate*</p><ol id="l7"><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Two things distinguish food production from all other productive activities: first, every single person needs food each day and has a right to it; and second, it is hugely dependent on nature. These two unique aspects, one political, the other natural, make food production highly vulnerable and different from any other business. At the same time, cultural values are highly entrenched in food and agricultural systems worldwide.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Farmers everywhere face major risks, including extreme weather, long-term climate change, and price volatility in input and product markets. However, smallholder farmers in developing countries must in addition deal with adverse environments, both natural, in terms of soil quality, rainfall, etc., and human, in terms of infrastructure, financial systems, markets, knowledge and technology. Counter-intuitively, hunger is prevalent among many smallholder farmers in the developing world.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Participants in the online debate argued that our biggest challenge is to address the underlying causes of the agricultural system’s inability to ensure sufficient food for all, and they identified as drivers of this problem our dependency on fossil fuels and unsupportive government policies.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">On the question of mitigating the risks farmers face, most essayists called for greater state intervention. In his essay, Kanayo F. Nwanze, President of the International Fund for Agricultural Development, argued that governments can significantly reduce risks for farmers by providing basic services like roads to get produce more efficiently to markets, or water and food storage facilities to reduce losses. Sophia Murphy, senior advisor to the Institute for Agriculture and Trade Policy, suggested that the procurement and holding of stocks by governments can also help mitigate wild swings in food prices by alleviating uncertainties about market supply.</p></li><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Shenggen Fan, Director General of the International Food Policy Research Institute, held up social safety nets and public welfare programmes in Ethiopia, Brazil and Mexico as valuable ways to address poverty among farming families and reduce their vulnerability to agriculture shocks. However, some commentators responded that cash transfers to poor families do not necessarily translate into increased food security, as these programmes do not always strengthen food production or raise incomes. Regarding state subsidies for agriculture, Rokeya Kabir, Executive Director of Bangladesh Nari Progati Sangha, commented in her essay that these ‘have not compensated for the stranglehold exercised by private traders. In fact, studies show that sixty percent of beneficiaries of subsidies are not poor, but rich landowners and non- farmer traders.’</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Nwanze, Murphy and Fan argued that private risk management tools, like private insurance, commodity futures markets, and rural finance can help small-scale producers mitigate risk and allow for investment in improvements. Kabir warned that financial support schemes often encourage the adoption of high-input agricultural practices, which in the medium term may raise production costs beyond the value of their harvests. Murphy noted that when futures markets become excessively financialised they can contribute to short-term price volatility, which increases farmers’ food insecurity. Many participants and commentators emphasised that greater transparency in markets is needed to mitigate the impact of volatility, and make evident whether adequate stocks and supplies are available. Others contended that agribusiness companies should be held responsible for paying for negative side effects.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Many essayists mentioned climate change and its consequences for small-scale agriculture. Fan explained that ‘in addition to reducing crop yields, climate change increases the magnitude and the frequency of extreme weather events, which increase smallholder vulnerability.’ The growing unpredictability of weather patterns increases farmers’ difficulty in managing weather-related risks. According to this author, one solution would be to develop crop varieties that are more resilient to new climate trends and extreme weather patterns. Accordingly, Pat Mooney, co-founder and executive director of the ETC Group, suggested that ‘if we are to survive climate change, we must adopt policies that let peasants diversify the plant and animal species and varieties/breeds that make up our menus.’</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Some participating authors and commentators argued in favour of community- based and autonomous risk management strategies through collective action groups, co- operatives or producers’ groups. Such groups enhance market opportunities for small- scale producers, reduce marketing  costs  and  synchronise buying  and  selling with seasonal price conditions. According to Murphy, ‘collective action offers an important way for farmers to strengthen their political and economic bargaining power, and to reduce their business risks.’ One commentator, Giel Ton, warned that collective action does not come as a free good. It takes time, effort and money to organise, build trust and</p></li></ol><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">to experiment. Others, like Marcel Vernooij and Marcel Beukeboom, suggested that in order to ‘apply what we already know’, all stakeholders, including business, government, scientists and civil society, must work together, starting at the beginning of the value chain.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">I Some participants explained that market price volatility is often worsened by the presence of intermediary purchasers who, taking advantage of farmers’ vulnerability, dictate prices. One commentator suggested farmers can gain greater control over prices and minimise price volatility by selling directly to consumers. Similarly, Sonali Bisht, founder and advisor to the Institute of Himalayan Environmental Research and Education (INHERE), India, wrote that community-supported agriculture, where consumers invest in local farmers by subscription and guarantee producers a fair price, is a risk-sharing model worth more attention. Direct food distribution systems not only encourage small-scale agriculture but also give consumers more control over the food they consume, she wrote.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: left;"><span class="s2" style=" background-color: #D9E1F3;"> THE LOST CITY                                                                                                             </span></p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;text-align: left;">An explorer’s encounter with the ruined city of Machu Picchu, the most famous icon of the Inca civilisation</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">14</p><ol id="l8"><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">When the US explorer and academic Hiram Bingham arrived in South America in 1911, he was ready for what was to be the greatest achievement of his life: the exploration of the remote hinterland to the west of Cusco, the old capital of the Inca empire in the Andes mountains of Peru. His goal was to locate the remains of a city called Vitcos, the last capital of the Inca civilisation. Cusco lies on a high plateau at an elevation of more than 3,000 metres, and Bingham’s plan was to descend from this plateau along the valley of the Urubamba river, which takes a circuitous route down to the Amazon and passes through an area of dramatic canyons and mountain ranges.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">15</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">When Bingham and his team set off down the Urubamba in late July, they had an advantage over travellers who had preceded them: a track had recently been blasted down the valley canyon to enable rubber to be brought up by mules from the jungle. Almost all previous travellers had left the river at Ollantaytambo and taken a high pass across the mountains to rejoin the river lower down, thereby cutting a substantial corner, but also therefore never passing through the area around Machu Picchu.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">16</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">On 24 July they were a few days into their descent of the valley. The day began slowly, with Bingham trying to arrange sufficient mules for the next stage of the trek. His companions showed no interest in accompanying him up the nearby hill to see some ruins that a local farmer, Melchor Arteaga, had told them about the night before. The morning was dull and damp, and Bingham also seems to have been less than keen on</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">the prospect of climbing the hill. In his book Lost City of the Incas, he relates that he made the ascent without having the least expectation that he would find anything at the top.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">17</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Bingham writes about the approach in vivid style in his book. First, as he climbs up the hill, he describes the ever-present possibility of deadly snakes, ‘capable of making considerable springs when in pursuit of their prey’; not that he sees any. Then there’s a sense of mounting discovery as he comes across great sweeps of terraces, then a mausoleum, followed by monumental staircases and, finally, the grand ceremonial buildings of Machu Picchu. ‘It seemed like an unbelievable dream ... the sight held me spellbound ...’ he wrote.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">18</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">We should remember, however, that Lost City of the Incas is a work of hindsight, not written until 1948, many years after his journey. His journal entries of the time reveal a much more gradual appreciation of his achievement. He spent the afternoon at the ruins noting down the dimensions of some of the buildings, then descended and rejoined his companions, to whom he seems to have said little about his discovery. At this stage, Bingham didn’t realise the extent or the importance of the site, nor did he realise what use he could make of the discovery.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">19</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">However, soon after returning it occurred to him that he could make a name for himself from this discovery. When he came to write the National Geographic magazine article that broke the story to the world in April 1913, he knew he had to produce a big idea. He wondered whether it could have been the birthplace of the very first Inca, Manco the Great, and whether it could also have been what chroniclers described as ‘the last city of the Incas’. This term refers to Vilcabamba, the settlement where the Incas had fled from Spanish invaders in the 1530s. Bingham made desperate attempts to prove this belief for nearly 40 years. Sadly, his vision of the site as both the beginning and end of the Inca civilisation, while a magnificent one, is inaccurate. We now know that Vilcabamba actually lies 65 kilometres away in the depths of the jungle.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">20</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">One question that has perplexed visitors, historians and archaeologists alike ever since Bingham, is why the site seems to have been abandoned before the Spanish Conquest. There are no references to it by any of the Spanish chroniclers - and if they had known of its existence so close to Cusco they would certainly have come in search of gold. An idea which has gained wide acceptance over the past few years is that Machu Picchu was a moya, a country estate built by an Inca emperor to escape the cold winters of Cusco, where the elite could enjoy monumental architecture and spectacular views. Furthermore, the particular architecture of Machu Picchu suggests that it was</p></li></ol><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">constructed at the time of the greatest of all the Incas, the emperor Pachacuti (c. 1438- 71). By custom, Pachacuti’s descendants built other similar estates for their own use, and so Machu Picchu would have been abandoned after his death, some 50 years before the Spanish Conquest.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;">  THE BENEFITS OF BEING BILINGUAL                                                                 </span></p><ol id="l9"><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">According to the latest figures, the majority of the world’s population is now bilingual or multilingual, having grown up speaking two or more languages. In the past, such children were considered to be at a disadvantage compared with their monolingual peers. Over the past few decades,  however, technological advances have allowed researchers to look more deeply at how bilingualism interacts with and changes the cognitive and neurological systems, thereby identifying several clear benefits of being bilingual.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Research shows that when a bilingual person uses one language, the other is active at the same time. When we hear a word, we don’t hear the entire word all at once: the sounds arrive in sequential order. Long before the word is finished, the brain’s language system begins to guess what that word might be. If you hear ‘can’, you will likely activate words like ‘candy’ and ‘candle’ as well, at least during the earlier stages of word recognition. For bilingual people, this activation is not limited to a single language; auditory input activates corresponding words regardless of the language to which they belong. Some of the most compelling evidence for this phenomenon, called ‘language co-activation’, comes from studying eye movements. A Russian-English bilingual asked to ‘pick up a marker’ from a set of objects would look more at a stamp than someone who doesn’t know Russian, because the Russian word for ‘stamp’, marka, sounds like the English word he or she heard, ‘marker’. In cases like this, language co- activation occurs because what the listener hears could map onto words in either language.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Having to deal with this persistent linguistic competition can result in difficulties, however. For instance, knowing more than one language can cause speakers to name pictures more slowly, and can increase ‘tip-of-the-tongue states’, when you can almost, but not quite, bring a word to mind. As a result, the constant juggling of two languages creates a need to control how much a person accesses a language at any given time. For this reason, bilingual people often perform better on tasks that require conflict management. In the classic Stroop Task, people see a word and are asked to name the colour of the word’s font. When the colour and the word match (i.e., the word ‘red’ printed in red), people correctly name the colour more quickly than when the colour and the word don’t match (i.e., the word ‘red’ printed in blue). This occurs because the word itself (‘red’) and its font colour (blue) conflict. Bilingual people often excel at tasks such as this, which tap into the ability to ignore competing perceptual information and focus on the relevant aspects of the input. Bilinguals are also better at switching between two tasks; for example, when bilinguals have to switch from categorizing objects by colour</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">(red or green) to categorizing them by shape (circle or triangle), they do so more quickly than monolingual people, reflecting better cognitive control when having to make rapid changes of strategy.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">It also seems that the neurological roots of the bilingual advantage extend to brain areas more traditionally associated with sensory processing. When monolingual and  bilingual adolescents  listen  to  simple speech sounds without  any  intervening background noise, they show highly similar brain stem responses. When researchers play the same sound to both groups in the presence of background noise, however, the bilingual listeners’ neural response is considerably larger, reflecting better encoding of the sound’s fundamental frequency, a feature of sound closely related to pitch perception.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Such improvements in cognitive and sensory processing may help a bilingual person to process information in the environment, and help explain why bilingual adults acquire a third language better than monolingual adults master a second language. This advantage may be rooted in the skill of focusing on information about the new language while reducing interference from the languages they already know.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Research also indicates that bilingual experience may help to keep the cognitive mechanisms sharp by recruiting alternate brain networks to compensate for those that become damaged during aging. Older bilinguals enjoy improved memory relative to monolingual people, which can lead to real-world health benefits. In a study of over 200 patients with Alzheimer’s disease, a degenerative brain disease, bilingual patients reported showing initial symptoms of the disease an average of five years later than monolingual patients. In a follow-up study, researchers compared the brains of bilingual and monolingual patients matched on the severity of Alzheimer’s symptoms. Surprisingly, the bilinguals’ brains had more physical signs of disease than their monolingual counterparts, even though their outward behaviour and abilities were the same. If the brain is an engine, bilingualism may help it to go farther on the same amount of fuel.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Furthermore, the benefits associated with bilingual experience seem to start very early. In one study, researchers taught seven-month-old babies growing up in monolingual or bilingual homes that when they heard a tinkling sound, a puppet appeared on  one side of  a screen. Halfway  through  the study, the puppet began appearing on the opposite side of the screen. In order to get a reward, the infants had to adjust the rule they’d learned; only the bilingual babies were able to successfully learn the new rule. This suggests that for very young children, as well as for older people, navigating a multilingual environment imparts advantages that transfer far beyond language.</p></li></ol><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">FLYING TORTOISES</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">12 TEST7</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">An airborne reintroduction programme has helped conservationists take significant steps to protect the endangered Galapagos tortoise.</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">1</p><ol id="l10"><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Forests of spiny cacti cover much of the uneven lava plains that separate the interior of the Galapagos island of lsabela from the Pacific Ocean. With its five distinct volcanoes, the island resembles a lunar landscape. Only the thick vegetation at the skirt of the often cloud-covered peak of Sierra Negra offers respite from the barren terrain below. This inhospitable environment is home to the giant Galapagos tortoise. Some time after the Galapagos’s birth, around five million years ago, the islands were colonised by one or more tortoises from mainland South America. As these ancestral tortoises settled on the individual islands, the different populations adapted to their unique environments, giving rise to at least 14 different subspecies. Island life agreed with them. In the absence of significant predators, they grew to become the largest and longest-living tortoises on the planet, weighing more than 400 kilograms, occasionally exceeding 1.8 metres in length and living for more than a century.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">2</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Before human arrival, the archipelago’s tortoises numbered in the hundreds of thousands. From the 17th century onwards, pirates took a few on board for food, but the arrival of whaling ships in the 1790s saw this exploitation grow exponentially. Relatively immobile and capable of surviving for months without food or water, the tortoises were taken on board these ships to act as food supplies during long ocean passages. Sometimes, their bodies were processed into high- grade oil. In total, an estimated 200,000 animals were taken from the archipelago before the 20th century. This historical exploitation was then exacerbated when settlers came to the islands. They hunted the tortoises and destroyed their habitat to clear land for agriculture. They also introduced alien species — ranging from cattle, pigs, goats, rats and dogs to plants and ants — that either prey on the eggs and young tortoises or damage or destroy their habitat.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">3</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Today, only 11 of the original subspecies survive and of these, several are highly endangered. In 1989, work began on a tortoise-breeding centre just outside the town of Puerto Villamil on Isabela, dedicated to protecting the island’s tortoise populations. The centre’s captive-breeding programme proved to be extremely successful, and it eventually had to deal with an overpopulation problem.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">4</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">The problem was also a pressing one. Captive-bred tortoises can’t be reintroduced into the wild until they’re at least five years old and weigh at least 4.5</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">kilograms, at which point their size and weight — and their hardened shells — are sufficient to protect them from predators. But if people wait too long after that point, the tortoises eventually become too large to transport.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">5</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">For years, repatriation efforts were carried out in small numbers, with the tortoises carried on the backs of men over weeks of long, treacherous hikes along narrow trails. But in November 2010, the environmentalist and Galapagos National Park liaison officer Godfrey Merlin, a visiting private motor yacht captain and a helicopter pilot gathered around a table in a small café in Puerto Ayora on the island of Santa Cruz to work out more ambitious reintroduction. The aim was to use a helicopter to move 300 of the breeding centre’s tortoises to various locations close to Sierra Negra.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">6</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">This unprecedented effort was made possible by the owners of the 67-metre yacht White Cloud, who provided the Galapagos National Park with free use of their helicopter and its experienced pilot, as well as the logistical support of the yacht, its captain and crew. Originally an air ambulance, the yacht’s helicopter has a rear double door and a large internal space that’s well suited for cargo, so a custom crate was designed to hold up to 33 tortoises with a total weight of about 150 kilograms. This weight, together with that of the fuel, pilot and four crew, approached the helicopter’s maximum payload, and there were times when it was clearly right on the edge of the helicopter’s capabilities. During a period of three days, a group of volunteers from the breeding centre worked around the clock to prepare the young tortoises for transport. Meanwhile, park wardens, dropped off ahead of time in remote locations, cleared landing sites within the thick brush, cacti and lava rocks</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">7</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Upon their release, the juvenile tortoises quickly spread out over their ancestral territory, investigating their new surroundings and feeding on the vegetation. Eventually, one tiny tortoise came across a fully grown giant who had been lumbering around the island for around a hundred years. The two stood side by side, a powerful symbol of the regeneration of an ancient species.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> THE INTERSECTION OF HEALTH SCIENCES AND GEOGRAPHY               </span></p><ol id="l11"><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">While many diseases that affect humans have been eradicated due to improvements in vaccinations and the availability of healthcare, there are still areas around the world where certain health issues are more prevalent. In a world that is far more globalized than ever before, people come into contact with one another through travel and living closer and closer to each other. As a result, super-viruses and other infections resistant to antibiotics are becoming more and more common.</p></li><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Geography can often play a very large role in the health concerns of certain populations. For instance, depending on where you live, you will not have the same health concerns as someone who lives in a different geographical region. Perhaps one of the most obvious examples of this idea is malaria-prone areas, which are usually tropical regions that foster a warm and damp environment in which the mosquitos that can give people this disease can grow. Malaria is much less of a problem in high-altitude deserts, for instance.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">In some countries, geographical factors influence the health and well-being of the population in very obvious ways. In many large cities, the wind is not strong enough to clear the air of the massive amounts of smog and pollution that cause asthma, lung problems, eyesight issues and more in the people who live there. Part of the problem is, of course, the massive number of cars being driven, in addition to factories that run on coal power. The rapid industrialization of some countries in recent years has also led to the cutting down of forests to allow for the expansion of big cities, which makes it even harder to fight the pollution with the fresh air that is produced by plants.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">It is in situations like these that the field of health geography comes into its own. It is an increasingly important area of study in a world where diseases like polio are re- emerging, respiratory diseases continue to spread, and malaria-prone areas are still fighting to find a better cure. Health geography is the combination of, on the one hand, knowledge regarding geography and methods used to analyse and interpret geographical information, and on the other, the study of health, diseases and healthcare practices around the world. The aim of this hybrid science is to create solutions for common geography-based health problems. While people will always be prone to illness, the study of how geography affects our health could lead to the eradication of certain illnesses, and the prevention of others in the future. By understanding why and how we get sick, we can change the way we treat illness and disease specific to certain geographical locations.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The geography of disease and ill health analyses the frequency with which certain diseases appear in different parts of the world, and overlays the data with the geography of the region, to see if there could be a correlation between the two. Health geographers also study factors that could make certain individuals or a population more likely to be taken ill with a specific health concern or disease, as compared with the population of another area. Health geographers in this field are usually trained as healthcare workers, and have an understanding of basic epidemiology as it relates to the spread of diseases among the population.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Researchers study the interactions between humans and their environment that could lead to illness (such as asthma in places with high levels of pollution) and work to create a clear way of categorizing illnesses, diseases and epidemics into local and global scales. Health geographers can map the spread of illnesses and attempt to identify</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">the reasons behind an increase or decrease in illnesses, as they work to find a way to halt the further spread or re-emergence of diseases in vulnerable populations.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The second subcategory of health geography is the geography of healthcare provision. This group studies the availability (or lack thereof) of healthcare resources to individuals and populations around the world. In both developed and developing nations there is often a very large discrepancy between the options available to people in different social classes, income brackets, and levels of education. Individuals working in the area of the geography of healthcare provision attempt to assess the levels of healthcare in the area (for instance, it may be very difficult for people to get medical attention because there is a mountain between their village and the nearest hospital). These researchers are on the frontline of making recommendations regarding policy to international organisations, local government bodies and others.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The field of health geography is often overlooked, but it constitutes a huge area of need in the fields of geography and healthcare. If we can understand how geography affects our health no matter where in the world we are located, we can better treat disease, prevent illness, and keep people safe and well.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> MUSIC AND THE EMOTIONS                                                                                   </span></p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">Neuroscientist Jonah Lehrer considers the emotional power of music</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Why does music make us feel? On the one hand, music is a purely abstract art form, devoid of language or explicit ideas. And yet, even though music says little, it still manages to touch us deeply. When listening to our favourite songs, our body betrays all the symptoms of emotional arousal. The pupils in our eyes dilate, our pulse and blood pressure rise, the electrical conductance of our skin is lowered, and the cerebellum, a brain region associated with bodily movement, becomes strangely active. Blood is even re-directed to the muscles in our legs. In other words, sound stirs us at our biological roots.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">A recent paper in Nature Neuroscience by a research team in Montreal, Canada, marks an important step in revealing the precise underpinnings of ‘the potent pleasurable stimulus&#39; that is music. Although the study involves plenty of fancy technology, including functional magnetic resonance imaging (FMRI) and ligand-based positron emission tomography (PET) scanning, the experiment itself was rather straightforward. After screening 217 individuals who responded to advertisements requesting people who experience ‘chills&#39; to instrumental music, the scientists narrowed down the subject pool to ten. They then asked the subjects to bring in their playlist of favourite songs - virtually every genre was represented, from techno to tango - and played them the music while their brain activity was monitored. Because the scientists were combining methodologies (PET and fMRI), they were able to obtain an impressively exact and detailed portrait of music in the brain. The first thing they discovered is that music triggers the production of dopamine - a chemical with a key</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">role in setting people&#39;s moods - by the neurons (nerve cells) in both the dorsal and ventral regions of the brain. As these two regions have long been linked with the experience of pleasure, this finding isn&#39;t particularly surprising.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">What is rather more significant is the finding that the dopamine neurons in the caudate - a region of the brain involved in learning stimulus-response associations, and in anticipating food and other ‘reward&#39; stimuli - were at their most active around 15 seconds before the participants&#39; favourite moments in the music. The researchers call this the ‘anticipatory phase&#39;<span class="s6">； </span>and argue that the purpose of this activity is to help us</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 13pt;text-align: justify;">predict the arrival of our favourite part. The question, of course, is what all these</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">dopamine neurons are up to. Why are they so active in the period preceding the acoustic climax? After all, we typically associate surges of dopamine with pleasure, with the processing of actual rewards. And yet, this cluster of cells is most active when the ‘chills&#39; have yet to arrive, when the melodic pattern is still unresolved.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">One way to answer the question is to look at the music and not the neurons. While music can often seem (at least to the outsider) like a labyrinth of intricate patterns, it turns out that the most important part of every song or symphony is when the patterns break down, when the sound becomes unpredictable. If the music is too obvious, it is annoyingly boring, like an alarm clock. Numerous studies, after all, have demonstrated that dopamine neurons quickly adapt to predictable rewards. If we know what’s going to happen next, then we don’t get excited. This is why composers often introduce a key note in the beginning of a song, spend most of the rest of the piece in the studious avoidance of the pattern, and then finally repeat it only at the end. The longer we are denied the pattern we expect, the greater the emotional release when the pattern returns, safe and sound.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">To demonstrate this psychological principle, the musicologist Leonard Meyer, in his classic book Emotion and Meaning in Music (1956), analysed the 5th movement of Beethoven&#39;s String Quartet in C-sharp minor, Op. 131. Meyer wanted to show how music is defined by its flirtation with - but not submission to - our expectations of order. Meyer dissected 50 measures (bars) of the masterpiece, showing how Beethoven begins with the clear statement of a rhythmic and harmonic pattern and then, in an ingenious tonal dance, carefully holds off repeating it. What Beethoven does instead is suggest variations of the pattern. He wants to preserve an element of uncertainty in his music, making our brains beg for the one chord he refuses to give us. Beethoven saves that chord for the end.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">According to Meyer, it is the suspenseful tension of music, arising out of our unfulfilled expectations, that is the source of the music&#39;s feeling. While earlier theories of music focused on the way a sound can refer to the real world of images and experiences - its ‘connotative&#39; meaning - Meyer argued that the emotions we find in music come from the unfolding events of the music itself. This ‘embodied meaning’</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">arises from the patterns the symphony invokes and then ignores. It is this uncertainty that triggers the surge of dopamine in the caudate, as we struggle to figure out what will happen next. We can predict some of the notes, but we can&#39;t predict them all, and that is what keeps us listening, waiting expectantly for our reward, for the pattern to be completed.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">THE HISTORY OF GLASS</p><p style="text-indent: 0pt;text-align: left;"/><p class="s5" style="padding-top: 1pt;padding-left: 4pt;text-indent: 0pt;line-height: 21pt;text-align: left;">剑 <span class="s1">12 TEST8</span></p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">From our earliest origins, man has been making use of glass. Historians have discovered that a type of natural glass — obsidian — formed in places such as the mouth of a volcano as a result of the intense heat of an eruption melting sand — was first used as tips for spears. Archaeologists have even found evidence of man-made glass which dates back to 4000 BC; this took the form of glazes used for coating stone beads. It was not until 1500 BC, however, that the first hollow glass container was made by covering a sand core with a layer of molten glass.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Glass blowing became the most common way to make glass containers from the first century BC. The glass made during this time was highly coloured due to the impurities of the raw material. In the first century AD, methods of creating colourless glass were developed, which was then tinted by the addition of colouring materials. The secret of glass making was taken across Europe by the Romans during this century. However, they guarded the skills and technology required to make glass very closely, and it was not until their empire collapsed in 476 AD that glass-making knowledge became widespread throughout Europe and the Middle East. From the 10th century onwards, the Venetians gained a reputation for technical skill and artistic ability in the making of glass bottles, and many of the city’s craftsmen left Italy to set up glassworks throughout Europe.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">A major milestone in the history of glass occurred with the invention of lead crystal glass by the English glass manufacturer George Ravenscroft (1632—1688). He attempted to counter the effect of clouding that sometimes occurred in blown glass by introducing lead to the raw materials used in the process. The new glass he created was softer and easier to decorate, and had a higher refractive index, adding to its brilliance and beauty, and it proved invaluable to the optical industry. It is thanks to Ravenscroft’s invention that optical lenses, astronomical telescopes, microscopes and the like became possible.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">In Britain, the modern glass industry only really started to develop after the repeal of the Excise Act in 1845. Before that time, heavy taxes had been placed on the amount of glass melted in a glasshouse, and were levied continuously from 1745 to 1845. Joseph Paxton&#39;s Crystal Palace at London’s Great Exhibition of 1851 marked the beginning of glass as a material used in the building industry. This revolutionary new building</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">encouraged the use of glass in public, domestic and horticultural architecture. Glass manufacturing techniques also improved with the advancement of science and the development of better technology.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">From 1887 onwards, glass making developed from traditional mouth-blowing to a semi-automatic process, after factory-owner HM Ashley introduced a machine capable of producing 200 bottles per hour in Castleford, Yorkshire, England — more than three times quicker than any previous production method. Then in 1907, the first fully automated machine was developed in the USA by Michael Owens — founder of the Owens Bottle Machine Company (later the major manufacturers Owens- Illinois) — and installed in its factory. Owens’ invention could produce an impressive 2,500 bottles per hour. Other developments followed rapidly, but it was not until the First World War, when Britain became cut off from essential glass suppliers, that glass became part of the scientific sector. Previous to this, glass had been seen as a craft rather than a precise science.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Today, glass making is big business. It has become a modern, hi-tech industry operating in a fiercely competitive global market where quality, design and service levels are critical to maintaining market share. Modern glass plants are capable of making millions of glass containers a day in many different colours, with green, brown and clear remaining the most popular. Few of us can imagine modern life without glass. It features in almost every aspect of our lives — in our homes, our cars and whenever we sit down to eat or drink. Glass packaging is used for many products, many beverages are sold in glass, as are numerous foodstuffs, as well as medicines and cosmetics.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Glass is an ideal material for recycling, and with growing consumer concern for green issues, glass bottles and jars are becoming ever more popular. Glass recycling is good news for the environment. It saves used glass containers being sent to landfill. As less energy is needed to melt recycled glass than to melt down raw materials, this also saves fuel and production costs. Recycling also reduces the need for raw materials to be quarried, thus saving precious resources.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> BRING BACK THE BIG CATS                                                                                   </span></p><p style="padding-top: 2pt;padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">It’s time to start returning vanished native animals to Britain, says John Vesty</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">There is a poem, written around 598 AD, which describes hunting a mystery animal called a llewyn. But what was it? Nothing seemed to fit, until 2006, when an animal bone, dating from around the same period, was found in the Kinsey Cave in northern England. Until this discovery, the lynx — a large spotted cat with tasselled ears — was presumed to have died out in Britain at least 6,000 years ago, before the inhabitants of these islands took up farming. But the 2006 find, together with three others in Yorkshire and Scotland, is compelling evidence that the lynx and the mysterious llewyn were in fact one and the same animal. If this is so, it would bring forward the tassel-eared cat&#39;s estimated extinction date by roughly 5,000 years.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 21pt;text-align: justify;">However, this is not quite the last glimpse of the animal in British culture. A 9th- century stone cross from the Isle of Eigg shows, alongside the deer, boar and aurochs pursued by a mounted hunter, a speckled cat with tasselled ears. Were it not for the animal’s backside having worn away with time, we could have been certain, as the lynx&#39;s stubby tail is unmistakable. But even without this key feature, it’s hard to see what else the creature could have been. The lynx is now becoming the totemic animal of a movement that is transforming British environmentalism: rewilding.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Rewilding means the mass restoration of damaged ecosystems. It involves letting trees return to places that have been denuded, allowing parts of the seabed to recover from trawling and dredging, permitting rivers to flow freely again. Above all, it means bringing back missing species. One of the most striking findings of modern ecology is that ecosystems without large predators behave in completely different ways from those that retain them. Some of them drive dynamic processes that resonate through the whole food chain, creating niches for hundreds of species that might otherwise struggle to survive. The killers turn out to be bringers of life.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Such findings present a big challenge to British conservation, which has often selected arbitrary assemblages of plants and animals and sought, at great effort and expense, to prevent them from changing. It has tried to preserve the living world as if it were a jar of pickles, letting nothing in and nothing out, keeping nature in a state of arrested development. But ecosystems are not merely collections of species; they are also the dynamic and ever-shifting relationships between them. And this dynamism often depends on large predators.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">At sea the potential is even greater: by protecting large areas from commercial fishing, we could once more see what 18th-century literature describes: vast shoals of fish being chased by fin and sperm whales, within sight of the English shore. This policy would also greatly boost catches in the surrounding seas; the fishing industry&#39;s insistence on scouring every inch of seabed, leaving no breeding reserves, could not be more damaging to its own interests.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Rewilding is a rare example of an environmental movement in which campaigners articulate what they are for rather than only what they are against. One of the reasons why the enthusiasm for rewilding is spreading so quickly in Britain is that it helps to create a more inspiring vision than the green movement&#39;s usual promise of ‘Follow us and the world will be slightly less awful than it would otherwise have been&#39;.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">The lynx presents no threat to human beings: there is no known instance of one preying on people. It is a specialist predator of roe deer, a species that has exploded in Britain in recent decades, holding back, by intensive browsing, attempts to re-establish forests. It will also winkle out sika deer: an exotic species that is almost impossible for human beings to control, as it hides in impenetrable plantations of young trees. The</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">attempt to reintroduce this predator marries well with the aim of bringing forests back to parts of our bare and barren uplands. The lynx requires deep cover, and as such presents little risk to sheep and other livestock, which are supposed, as a condition of farm subsidies, to be kept out of the woods.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">On a recent trip to the Cairngorm Mountains, I heard several conservationists suggest that the lynx could be reintroduced there within 20 years. If trees return to the bare hills elsewhere in Britain, the big cats  could soon follow. There is nothing extraordinary about these proposals, seen from the perspective of anywhere else in Europe. The lynx has now been reintroduced to the Jura Mountains, the Alps, the Vosges in eastern France and the Harz mountains in Germany, and has re-established itself in many more places. The European population has tripled since 1970 to roughly 10,000. As with wolves, bears, beavers, boar, bison, moose and many other species, the lynx has been able to spread as farming has left the hills and people discover that it is more lucrative to protect charismatic Wildlife than to hunt it, as tourists will pay for the chance to see it. Large-scale rewilding is happening almost everywhere — except Britain.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 21pt;text-align: justify;">Here, attitudes are just beginning to change. Conservationists are starting to accept that the old preservation-jar model is failing, even on its own terms. Already, projects such as Trees for Life in the Highlands provide a hint of what might be coming. An organisation is being set up that will seek to catalyse the rewilding of land and sea across Britain, its aim being to reintroduce that rarest of species to British ecosystem: hope.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 5pt;text-indent: 0pt;text-align: justify;"><span class="s2" style=" background-color: #D9E1F3;"> UK COMPANIES NEED MORE EFFECTIVE BOARDS OF DIRECTORS       </span></p><ol id="l12"><li><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">After a number of serious failures of governance (that is, how they are managed at the highest level), companies in Britain, as well as elsewhere, should consider radical changes to their directors’ roles. It is clear that the role of a board director today is not an easy one. Following the 2008 financial meltdown, which resulted in a deeper and more prolonged period of economic downturn than anyone expected, the search for explanations in the many post-mortems of the crisis has meant blame has been spread far and wide. Governments, regulators, central banks and auditors have all been in the frame. The role of bank directors and management and their widely publicised failures have been extensively picked over and examined in reports, inquiries and commentaries.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">28</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The knock-on effect of this scrutiny has been to make the governance of companies in general an issue of intense public debate and has significantly increased the pressures on, and the responsibilities of, directors. At the simplest and most practical level, the time involved in fulfilling the demands of a board directorship has increased significantly, calling into question the effectiveness of the classic model of corporate governance by part-time, independent non-executive directors. Where once a board schedule may have consisted of between eight and ten meetings a year, in many</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">companies the number of events requiring board input and decisions has dramatically risen. Furthermore, the amount of reading and preparation required for each meeting is increasing. Agendas can become overloaded and this can mean the time for constructive debate must necessarily be restricted in favour of getting through the business.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">29</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Often, board business is devolved to committees in order to cope with the workload, which may be more efficient but can mean that the board as a whole is less involved in fully addressing some of the most important issues. It is not uncommon for the audit committee meeting to last longer than the main board meeting itself. Process may take the place of discussion and be at the expense of real collaboration, so that boxes are ticked rather than issues tackled.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">30</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">A radical solution, which may work for some very large companies whose businesses are extensive and complex, is the professional board, whose members would work up to three or four days a week, supported by their own dedicated staff and advisers. There are obvious risks to this and it would be important to establish clear guidelines for such a board to ensure that it did not step on the toes of management by becoming too engaged in the day-to-day running of the company. Problems of recruitment, remuneration and independence could also arise and this structure would not be appropriate for all companies. However, more professional and better-informed boards would have been particularly appropriate for banks where the executives had access to information that part-time non-executive directors lacked, leaving the latter unable to comprehend or anticipate the 2008 crash.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">31</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">One of the main criticisms of boards and their directors is that they do not focus sufficiently on longer-term matters of strategy, sustainability and governance, but instead concentrate too much on short-term financial metrics. Regulatory requirements and the structure of the market encourage this behaviour. The tyranny of quarterly reporting can distort board decision-making, as directors have to ’make the numbers’ every four months to meet the insatiable appetite of the market for more data. This serves to encourage the trading methodology of a certain kind of investor who moves in and out of a stock without engaging in constructive dialogue with the company about strategy or performance, and is simply seeking a short- term financial gain. This effect has been made worse by the changing profile of investors due to the globalisation of capital and the increasing use of automated trading systems. Corporate culture adapts and management teams are largely incentivized to meet financial goals.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">32</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">Compensation for chief executives has become a combat zone where pitched battles between investors, management and board members are fought, often behind</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">closed doors but increasingly frequently in the full glare of press attention. Many would argue that this is in the interest of transparency and good governance as shareholders use their muscle in the area of pay to pressure boards to remove underperforming chief executives. Their powers to vote down executive remuneration policies increased when binding votes came into force. The chair of the remuneration committee can be an exposed and lonely role, as Alison Carnwath, chair of Barclays Bank’s remuneration committee, found when she had to resign, having been roundly criticised for trying to defend the enormous bonus to be paid to the chief executive; the irony being that she was widely understood to have spoken out against it in the privacy of the committee.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: left;">33</p></li><li><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The financial crisis stimulated a debate about the role and purpose of the company and a heightened awareness of corporate ethics. Trust in the corporation has been eroded and academics such as Michael Sandel, in his thoughtful and bestselling book What Money Can’t Buy, are questioning the morality of capitalism and the market economy. Boards of companies in all sectors will need to widen their perspective to encompass these issues and this may involve a realignment of corporate goals. We live in challenging times.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 3pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">SCIENCEDAILY</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"/><p class="s8" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">NEW ISLANDS, HAPPY FEET: STUDY REVEALS ISLAND FORMATION A KEY DRIVER OF PENGUIN SPECIATION</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;line-height: 15pt;text-align: justify;">Ever since Darwin first set foot on the Galapagos, evolutionary biologists have long</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">known that the geographic isolation of archipelogos has helped spur the formation of new species.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Now, an international research team led by Theresa Cole at the University of Otago, New Zealand, has found the same holds true for penguins. They have found the first compelling evidence that modern penguin diversity is driven by islands, despite spending the majority of their lives at sea.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;We propose that this diversification pulse was tied to the emergence of islands, which created new opportunities for isolation and speciation,&quot; said Cole.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Over the last 5 million years, during the Miocene period, (particularly within the last 2 million years), island emergence in the Southern Hemisphere has driven several branches on the penguin evolutionary tree, and also drove the more recent influence of human-caused extinctions of two recently extinct penguin species from New Zealand&#39;s Chatham Islands.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;Our findings suggest that these taxa were extirpated shortly after human settlement on the Chatham Islands,&quot; said Cole. &quot;These findings thus potentially represent important new examples of human-driven, Holocene extinction in the Pacific.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;While our results reinforce the importance of islands in generating biodiversity, they also underscore the role of humans as agents of biodiversity loss, especially via the extinction of island-endemic taxa,&quot; said Cole. As many of the bones were from middens, our results provide direct evidence that our newly discovered extinct taxa was hunted by humans.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The publication appears in the advanced online edition of the journal Molecular Biology and Evolution.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">About 20 modern penguin species exist, from the Antarctic emperor penguin, the forest dwelling Fiordland penguin and the tropical Galapagos penguin. A fossil record of more than 50 species can trace back penguin history to more than 60 million years ago -- indicating that penguin diversity may have once been much higher than today.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Using historical skin samples and subfossils from natural history museums, along with blood samples, the researchers performed the largest survey to date, across all penguin taxa.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The team tested their island hypotheses using 41 near-complete mitochondrial genomes, representing all extant and recently extinct penguin taxa. They calibrated their mitogenomic evolution to make an evolutionary clock based on the fossil record.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;By using well-justified fossil calibrations, we resolve the timing and mechanisms of modern penguin diversification,&quot; said Cole.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">They found that the two largest-bodied and most polar-adapted penguins are sister to all other living penguins. The DNA evidence also showed that genetically similar penguin species may be at the earlies stages of diversification.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The study provides important new data and perspectives to the debate on the origins of penguin diversity. It will also help better understand the role of islands as drivers of speciation to other animals and marine life.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-bottom: 1pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">The new taxa have been named Eudyptes warhami and Megadyptes antipodes richdalei after John Warham and Lance Richdale, pioneers in penguin biology.</p><p class="s8" style="padding-top: 2pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">REVISING THE HISTORY OF BIG, CLIMATE-ALTERING VOLCANIC ERUPTIONS</p><p style="padding-left: 5pt;text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;line-height: 15pt;text-align: left;">For all their destructive power, most volcanic eruptions are local events. Lava flows</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: left;">tend to reach only a few miles at most, while airborne ash and soot travel a little farther. But occasionally, larger eruptions can launch particles into the stratosphere, more than</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">6 miles above Earth&#39;s surface. The 1991 eruption of Mount Pinatubo in the Philippines</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">-- the world&#39;s largest eruption in the past 100 years -- is a prime example of a stratospheric eruption.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">When volcanic particles reach the stratosphere they stay aloft for a long time, reflecting sunlight and temporarily cooling the planet. By understanding the history of these big eruptions, researchers can begin to place short cooling episodes and other discrete climate events into the context of large-scale climate patterns.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Researchers working at the University of Maryland, the Université Grenoble Alpes in France, the Ecole Normale Supérieure in France and the Tokyo Institute of Technology have devised a new, more accurate system for identifying large stratospheric eruptions recorded in the layers of Antarctic ice cores.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Using their method, the researchers made some important revisions to the known history of big eruptions -- correcting the record on several misidentified events while discovering a few as yet unknown stratospheric eruptions. The researchers described their approach, which identifies airborne volcanic particles with a specific chemical signature, in a paper published January 28, 2019, in the journal Nature Communications.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;I find it very exciting that we are able to use chemical signals to build a highly accurate record of large, climate-relevant stratospheric eruptions,&quot; said James Farquhar, a professor of geology at UMD and a co-author of the research paper. &quot;This historical record will be highly useful for climate scientists seeking to understand the role of large eruptions in climate oscillations. But there is also the basic marvel of reading a chemical fingerprint that is left behind in ice.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Eventually, volcanic particles fall from the stratosphere, settling on the ground below. When they land on snow, the particles get covered up by more snow that gets compacted into ice. This preserves a record of the eruption that survives until the ice melts. Researchers can drill and retrieve ice cores in places like Antarctica and Greenland, revealing eruption records that stretch back several thousand years.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Because particles from large stratospheric eruptions can spread across the globe before falling to the ground, previous methods identified stratospheric eruptions by looking for sulfate particle layers in ice from both hemispheres -- usually from Antarctica and Greenland. If the same layers of sulfate showed up in both cores, deposited at the same time in Earth&#39;s history, researchers would conclude that the particles came from the same large, stratospheric eruption.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;For eruptions that are intense enough to inject material into the stratosphere, there is a telltale signature in the sulfur isotope ratios of sulfate preserved in ancient ice layers,&quot; explained Farquhar, who also has an appointment in UMD&#39;s Earth System Science</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Interdisciplinary Center. &quot;By instead focusing on this distinct sulfur isotope signature, our new method yielded some surprising and useful results. We found that prior reconstructions missed some stratospheric events and falsely identified others.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The study&#39;s lead author, Elsa Gautier from the Université Grenoble Alpes, did  a significant portion of the analyses at UMD while on a Fulbright scholarship to work with Farquhar in 2013. Following Gautier&#39;s lead, the researchers developed their method using ice cores collected at a remote site in Antarctica called Dome C. One of the highest points on the Antarctic ice sheet, Dome C is home to ice layers that stretch back nearly 50,000 years.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Gautier and her colleague Joel Savarino, also at the Université Grenoble Alpes, collected ice cores at Dome C that contain records stretching back roughly 2,600 years, covering a large portion of recorded human history.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The researchers used their method to confirm that many events had indeed been properly identified by the older method of matching up corresponding sulfate layers in ice cores from both hemispheres. But some events, formerly thought to be big stratospheric eruptions, did not have the telltale sulfur isotope signature in their sulfate layers. Instead, the researchers concluded, these layers must have been deposited by two or more smaller volcanoes that erupted at about the same time at high latitudes in both hemispheres.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The researchers also found some big stratospheric events that contain the isotope signature, but were somehow constrained to the Southern Hemisphere.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;This is a strength of our approach, because these events would have a climate impact but are missed by other methods,&quot; Farquhar said. &quot;We have made a significant improvement to the reconstruction of large stratospheric eruptions that occurred over the past 2,600 years. This is critically important for understanding the role of volcanic eruptions on climate and possibly for understanding certain events in human history, such as widespread famines. It can also help to inform future climate models that will take large volcanic events into account.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:8.5pt" cellspacing="0"><tr style="height:27pt"><td style="width:73pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 1pt;text-indent: 0pt;text-align: left;">SCALING</p></td><td style="width:33pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">UP</p></td><td style="width:72pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">SEARCH</p></td><td style="width:43pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">FOR</p></td><td style="width:99pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">ANALOGIES</p></td><td style="width:65pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">COULD</p></td><td style="width:33pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">BE</p></td><td style="width:43pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">KEY</p></td><td style="width:33pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 6pt;text-indent: 0pt;text-align: left;">TO</p></td></tr><tr style="height:8pt"><td style="width:494pt" colspan="9"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:27pt"><td style="width:494pt" colspan="9" bgcolor="#D9E1F3"><p class="s4" style="padding-left: 1pt;text-indent: 0pt;text-align: left;">INNOVATION</p></td></tr></table><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Investment in research is at an all-time high, yet the rate of scientific breakthroughs isn&#39;t setting any records. To resolve this quandary, scientists are turning to artificial intelligence and crowdsourcing for help in identifying a key inspiration for innovation</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">-- the perfect analogy.</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">Wilbur Wright, for instance, famously got his idea for using wing warping to balance an airplane while twisting a cardboard box. Using similar methods to solve disparate problems is a common theme in the history of innovation. But as problems become more complex and the amount of scientific information explodes, finding helpful analogies can be difficult, said Niki Kittur, a professor in Carnegie Mellon University&#39;s Human- Computer Interaction Institute.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">As described in a new report to be published online this week by the Proceedings of the National Academy of Sciences, researchers are addressing this problem by breaking down the process of identifying analogies, using crowd workers to solve individual steps in the process and training AIs to do part of the work automatically.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;We&#39;re developing new tools that could unlock a whole set of interesting possibilities,&quot; said Kittur, the lead author. &quot;We&#39;re just beginning to see how people might use them.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">If this approach proves successful, researchers need not rely on a lone genius such as Wright to find analogies. Instead, they can use a mix of individuals and AIs, each doing those portions of the work that leverage their particular strengths, said the authors, who include scientists from CMU, the Bosch Research and Technology Center in Pittsburgh, the Hebrew University of Jerusalem, the University of Maryland and New York University Stern School of Business.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Coordinating those efforts can be a challenge, they acknowledge, but better analogies could yield more efficient scientific discovery, potentially making scientific advances more profound and less incremental.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;People are really interested in how we start generating breakthroughs again,&quot; said Dafna Shahaf, assistant professor of computer science at Hebrew University of Jerusalem. &quot;The pace of discovery is high, but does not scale with the amount of resources invested in research.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">People, such as crowd workers on Amazon Mechanical Turk, have been key to the research, though AI can learn from their efforts and assume a larger role moving forward. For instance, the authors developed an AI tool that enables a designer to specify a focus of a product description and then abstract it in a targeted manner. A designer developing an adjustable soap dish, for example, could identify the focus as an extendable product for different sizes of soap. The focus could then be broadened to include different types of personal products or to accommodate dimensions such as heights or weights, rather than just length.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The researchers have shown how this approach can be extended to scientific research. That includes developing methods for novices to annotate scientific literature, which can be challenging to read and understand. Even so, nonexperts often can discern where</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">the most important concepts and mechanisms are in these research reports, even if they don&#39;t grasp what those concepts/mechanisms mean, said Joel Chan, assistant professor of information studies at the University of Maryland.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;Knowing which parts are important buys us a lot in terms of finding subtle analogical relationships between research papers,&quot; Chan added. For example, once nonexperts isolate the parts of papers that describe their purpose or research goal, AI models can identify other papers that are about common purposes, even if they are from different topic areas.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">If analogy identification can be scaled up, the potential for advances is great, said Hila Lifshitz-Assaf, assistant professor of information, operations and management sciences at NYU Stern. Waiting to be tapped are more than 9 million U.S. patents; more than 2 million product and solution ideas submitted to ideation platforms such as InnoCentive, Kickstarter, Quirky and OpenIDEO; hundreds of millions of scientific papers and legal cases searchable on Google Scholar; and billions of webpages and videos searchable on the internet.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Of course, the sheer volume of that information poses a challenge to finding and applying analogies, one of three challenges the authors identify. Another is the tendency of people to fixate on surface-level details, rather than deeper concepts that apply across fields. People considering how to treat an inoperable tumor with radiation without destroying healthy tissue, for instance, tend to focus on radiation or cancer rather than drawing inspiration from military science for multipronged assaults.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">A third challenge is the sheer complexity of real-world problems, which might require solutions of several subproblems, requiring multiple analogies at multiple levels of abstraction.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Solving those challenges could usher in a new era of discovery, Kittur said, providing people with the inspiration necessary to make breakthroughs now just beyond our reach.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;It could be that the low-hanging fruit has been plucked and we just don&#39;t have the ladders to reach what remains,&quot; he explained. &quot;AI will help us get higher into the tree, but you&#39;ll still need people to actually pick the fruit.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The National Science Foundation, Bosch, Google, the Israel Science Foundation, the HUJI Cyber Security Research Center and the Industrial Research Institute supported this research.</p><p style="padding-left: 10pt;text-indent: 0pt;line-height: 16pt;text-align: justify;">Word order predicts a native speakers&#39; working memory</p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Memory plays a crucial role in our lives, and several studies have already investigated how we store and retrieve information under different conditions. Typically, stimuli presented at the beginning and at the end of a list are recalled better than stimuli from</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">the middle. But are these findings universal and generalizable across languages and cultures?</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The group, including psychologists, linguists and biologists from five different countries, traveled across the world to run memory tests in eight different human cultures speaking different languages. &quot;The best part of this project was to cross deserts and seas to reach amazing people speaking the most wonderful languages ever, from Sidaama, to Khoekhoe and Khmer,&quot; says Amici, &quot;and know that these languages may provide them with a unique vision of the world.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The relationship between language and thought is controversial. One hypothesis is that language fosters habits of processing information that are retained even in non-linguistic domains. Languages, for instance, vary in their branching direction. In typical right- branching (RB) languages, like Italian, the head of the sentence usually comes first, followed by a sequence of modifiers that provide additional information about the head (e.g. &quot;the man who was sitting at the bus stop&quot;). In contrast, in left-branching (LB) languages, like Japanese, modifiers generally precede heads (e.g. &quot;who was sitting at the bus stop, the man&quot;). In RB languages, speakers could process information incrementally, given that heads are presented first and modifiers rarely affect previous parsing decisions. In contrast, LB structures can be highly ambiguous until the end, because initial modifiers often acquire a clear meaning only after the head has been parsed. Therefore, LB speakers may need to retain initial modifiers in working memory until the head is encountered to comprehend the sentence.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">By providing participants with a series of classic memory tasks, the research team could compare their performance when recalling words, numbers and spatial stimuli. &quot;The main finding of the study is that left-branching speakers were better at remembering initial stimuli across verbal and non-verbal working memory tasks, probably because real-time sentence comprehension heavily relies on retaining initial information in LB languages, but not in RB languages,&quot; says Alejandro Sanchéz Amaro, currently in the Department of Cognitive Science at the University of California, San Diego.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The main novelty of this study is that the link between language and thought might not be just confined to conceptual representations and semantic biases, but rather extend to syntax and its role in our way of processing sequential information. The language we speak affects the way we process, store and retrieve information. The fact that branching and word order may be linked to such a fundamental cognitive process like memory opens up new exciting avenues for psycholinguistic research towards expanding the pool of languages and populations investigated. &quot;What about the working memory of speakers of languages with mixed branching or free word order? Would we find people who are equally good at remembering initial and final items? And maybe at remembering the items in the middle?&quot; says Federico Rossano, from the University of California, San Diego. With more than 7,000 languages in the world, we have a uniquely</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">rich pool to study the relation between language and cognition. Preserving and investigating the wealth of this diversity is not only ethical, but also scientifically crucial to ultimately understand which factors shape the way we think and better comprehend the relation between language and thought.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><table style="border-collapse:collapse;margin-left:7pt" cellspacing="0"><tr style="height:27pt"><td style="width:493pt" bgcolor="#D9E1F3"><p class="s4" style="padding-top: 3pt;padding-left: 3pt;text-indent: 0pt;text-align: left;">MINDFULNESS AND SLEEP CAN REDUCE EXHAUSTION IN</p></td></tr><tr style="height:8pt"><td style="width:493pt"><p style="text-indent: 0pt;text-align: left;"><br/></p></td></tr><tr style="height:27pt"><td style="width:493pt" bgcolor="#D9E1F3"><p class="s4" style="padding-left: 3pt;text-indent: 0pt;text-align: left;">ENTREPRENEURS</p></td></tr></table><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">When entrepreneurs are feeling exhausted but can&#39;t afford the time for adequate sleep, they may be able to replenish their energy with mindfulness exercises such as meditation, new research from Oregon State University indicates.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;You can&#39;t replace sleep with mindfulness exercises, but they might help compensate and provide a degree of relief,&quot; said Charles Murnieks, an assistant professor of strategy and entrepreneurship in OSU&#39;s College of Business and the study&#39;s lead author. &quot;As little as 70 minutes a week, or 10 minutes a day, of mindfulness practice may have the same benefits as an extra 44 minutes of sleep a night.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The findings were published recently in the Journal of Business Venturing. Co-authors include Jonathan Arthurs, Nusrat Farah and Jason Stornelli of OSU; Melissa Cardon of the University of Tennessee; and J. Michael Haynie of Syracuse University.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Entrepreneurs are generally defined as people involved in the discovery, evaluation and exploitation of new business opportunities, often with a stake in the ownership of new ventures. Entrepreneurship can be exhilarating, but it also can be difficult, stressful and tiring work. &quot;You can only work so hard for so long,&quot; Murnieks said.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Generally, when people are feeling exhausted, their drive to achieve goals is lowered, they have less desire to complete work tasks and they may find it harder to rise to and address challenges, all of which are important processes of entrepreneurship.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Exhaustion is a pervasive problem for entrepreneurs working on new ventures, but there is little existing research exploring the levels of exhaustion experienced by this group or how they handle it. In their research, Murnieks and his co-authors sought to explore ways entrepreneurs deal with the exhaustion that comes with the work.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">In a study of 105 entrepreneurs from around the U.S., the researchers asked participants about their exhaustion levels; whether they engaged in mindfulness practices and if so, how often and for how long; and how many hours they slept each night.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">More than 40 percent of the participants reported working 50 hours per week or more, on average, and sleeping less than 6 hours a night. The researchers found that the</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">entrepreneurs who slept more, or who engaged in the highest levels of mindfulness exercises, reported lower levels of exhaustion.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">In a second study of 329 entrepreneurs, the researchers again asked about mindfulness practice, perceived exhaustion and sleep. The study confirmed the findings of the initial study, that mindfulness can combat feelings of exhaustion.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">However, in both studies, Murnieks and his colleagues also found that mindfulness exercises are less helpful if you&#39;re getting adequate sleep but still feeling exhausted. When someone is experiencing perceived exhaustion, they are typically feeling a lack of energy at work and as though their resources are depleted.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;If you&#39;re feeling stressed and not sleeping, you can compensate with mindfulness exercises to a point,&quot; Murnieks said. &quot;But when you&#39;re not low on sleep, mindfulness doesn&#39;t improve those feelings of exhaustion.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Mindfulness exercises and sleep are thought to work differently to reduce exhaustion. Mindfulness works to modify and reduce stressors before they lead to exhaustion, while sleep works to replenish energy and self-control after the depletion has occurred, but before exhaustion is felt.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">More research is needed to better understand how mindfulness exercises may help weary entrepreneurs and the limits of those beneficial effects, Murnieks said, but there is indication mindfulness can provide a boost.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="662" height="81" alt="image" src="66篇/Image_002.png"/></span></p><p style="padding-top: 3pt;padding-left: 4pt;text-indent: 0pt;text-align: left;">THE DANGERS OF HIDDEN FAT: EXERCISE IS YOUR BEST DEFENSE</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 4pt;text-indent: 0pt;text-align: left;">AGAINST DEEP ABDOMINAL FAT</p><p style="text-indent: 0pt;text-align: left;"/><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;There are times when you&#39;re launching a new venture that you&#39;re going to have to surge,&quot; he said. &quot;Mindfulness exercises may be one way to provide some relief during those tough stretches.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Scientists know that the type of fat you can measure with a tape isn&#39;t the most dangerous. But what is the most effective way to fight internal, visceral fat that you cannot see or feel? The answer: exercise.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Researchers at UT Southwestern Medical Center analyzed two types of interventions -- lifestyle modification (exercise) and pharmacological (medicine) -- to learn how best to defeat fat lying deep in the belly. The study is published in Mayo Clinic Proceedings.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;Visceral fat can affect local organs or the entire body system. Systemically it can affect your heart and liver, as well as abdominal organs,&quot; said senior author and cardiologist Dr. Ian J. Neeland, Assistant Professor of Internal Medicine. &quot;When studies use weight</p><p style="padding-top: 3pt;padding-left: 10pt;text-indent: 0pt;text-align: justify;">or body mass index as a metric, we don&#39;t know if the interventions are reducing fat everywhere in the body, or just near the surface.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">To find out, the researchers evaluated changes in visceral fat in 3,602 participants over a 6-month period measured by a CT or MRI exam. Both exercise and medicines resulted in less visceral fat, but the reductions were more significant per pound of body weight lost with exercise.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">&quot;The location and type of fat is important. If you just measure weight or BMI, you can underestimate the benefit to your health of losing weight,&quot; said Dr. Neeland, a Dedman Family Scholar in Clinical Care. &quot;Exercise can actually melt visceral fat.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Participants in exercise trials were 65 percent female, with a mean age of 54 and mean BMI at enrollment of 31. Exercise regimens were monitored, not self-reported. The majority of exercise trials were performed in the U.S. and Canada, while pharmacologic trials included the U.S., Canada, Sweden, Japan, and four multinational cohorts.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">The medications used by study participants were FDA approved or in the FDA approval pipeline.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">According to the Centers for Disease Control and Prevention, obesity affects nearly 40 percent of adult Americans. Dr. Neeland said researchers previously thought of fat as inert storage, but over the years this view evolved and fat is now seen as an active organ. &quot;Some people who are obese get heart disease, diabetes, or metabolic syndrome -- and others don&#39;t,&quot; Dr. Neeland said. &quot;Our study suggests that a combination of approaches can help lower visceral fat and potentially prevent these diseases.&quot;</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 10pt;text-indent: 0pt;text-align: justify;">Other UT Southwestern researchers who contributed to this work include Dr. Shreya Rao, cardiology fellow; Dr. Ambarish Pandey, Assistant Professor of Internal Medicine; Dr. Bryan Park, internal medicine resident; Helen Mayo, Faculty Associate; Dr. Dharam Kumbhani, Associate Professor of Internal Medicine; and Dr. James A. de Lemos, Professor of Internal Medicine. Dr. de Lemos holds the Sweetheart Ball-Kern Wildenthal, M.D., Ph.D., Distinguished Chair in Cardiology.</p></body></html>
